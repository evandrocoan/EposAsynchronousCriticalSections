!::Predictable Synchronization Algorithms %%% for Asynchronous Critical Sections::
::Evandro Sperfeld Coan <evandrocoan@hotmail.com>::
::Eduardo Demeneck Onghero <do.demeneck@gmail.com>::

{maketoc}

!!Motivação  [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]
A abordagem tradicional para a coordenação do acesso à recursos compartilhados em ambientes multi thread envolve a utilização de algoritmos bloqueantes de sincronização. Esses algoritmos forçam threads a bloquearem nos casos de disputas no acesso à recursos compartilhados.

Uma outra abordagem possível envolve o uso de algoritmos baseados em delegação e sincronização não bloqueante para a coordenação de threads. Com esse tipo de algoritmo, threads delegam a execução de operações envolvendo acessos a recursos compartilhados à outras threads. A sincronização não bloqueante é utilizada para garantir certas propriedades às operações dos algoritmos baseados em delegação, de modo a evitar problemas decorrentes do bloqueio de threads, como variações de latência e inversões de prioridade, altamente relevantes no contexto de sistemas embarcados multi core, que, por interagirem diretamente com objetos físicos, possuem necessidades diferenciadas de latência e throughput.

!!Objetivos  [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]
O objetivo principal deste trabalho é a implementação de um algoritmo de sincronização com suporte à seções críticas assíncronas.

!!!Objetos específicos  [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]
*Implementação de um algoritmo de sincronização baseado em delegação para seções críticas assíncronas, utilizando o conceito seções guardadas.
*Implementação de uma nova versão do algoritmo com suporte para seções críticas síncronas.
*Realização de testes para avaliar a corretude dos algoritmos implementados.

!!Metodologia  [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]
Será realizada uma pesquisa na literatura com foco nos conceitos básicos que fundamentam algoritmos de sincronização para seções críticas assíncronas, de modo a compreender detalhes de funcionamento desse tipo de algoritmo e então decidir sobre a melhor maneira de implementá-los no EPOS.

Após entendidos claramente os conceitos, o desenvolvimento seguirá com a metodologia programar e testar (Cowboy Coding), que consiste em escrever um pedaço de código e testar sua execução, verificando se o resultado consiste com o esperado. Os programas de teste serão programas simples, que permitam verificar se o sistema está respondendo corretamente às expectativas.

!!Cronograma  [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]
||
Tarefa       | 01/10 | 08/10 | 22/10 | 05/11 | 19/11 | 26/11 | 21-28/11
T0           | D0    |       |       |       |       |       |
T1           |       | D1    |       |       |       |       |
T2           |       |       | D2    |       |       |       |
T3           |       |       |       | D3    |       |       |
T4           |       |       |       |       | D4    |       |
T5           |       |       |       |       |       | D5    |
Apresentação |       |       |       |       |       |       | Ap
||

!!Tarefas e Entregáveis  [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]

!!!T0 - Planejamento  [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]
* Escrever o plano de projeto detalhado, contendo uma fundamentação teórica robusta, apresentando os conceitos chave relacionados à algoritmos de sincronização para seções críticas assíncronas, assim como exemplos de algoritmos desse tipo.  Além disso, o plano deve conter o detalhamento do projeto, explicando o que será feito durante o semestre e quais entregáveis serão produzidos.
* Escrever programas de teste que provem a viabilidade do projeto, demonstrando que as operações CAS e FAS, necessárias para a implementação do algoritmo, são suportadas pelo EPOS.
__Entregável: D0__
# Plano de projeto
## Descrição da metodologia adotada.
## Lista de tarefas/entregáveis para cada entrega com seu cronograma.
## Fundamentação teórica.

!!!T1 - Revisão do Planejamento  [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]
* Realizar as correções no plano de projeto com base no feedback obtido no D0.
__Entregável: D1__
# Plano de projeto revisado.

!!!T2 - Implementação I  [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]
* Implementação de um novo componente de sincronização no EPOS. Esse componente será responsável por prover mecanismos para a execução não bloqueante de seções críticas assíncronas. Uma limitação dessa primeira versão do componente está relacionada aos tipos de seções críticas suportadas, que no caso serão apenas seções críticas assíncronas. Isso porque, o suporte a seções críticas síncronas exige a utilização de mecanismos para a sincronização unilateral de threads, que serão o tema principal da tarefa T3.
* Definição de uma convenção de programação, que poderá ser utilizada por threads do EPOS para solicitar a execução assíncronas de seções críticas, e que juntamente com o componente Guard, compõe um sistema de execução que possibilita a execução de seções críticas assíncronas de maneira não bloqueante.
__Entregável: D2__
# Novo componente de sincronização do EPOS, o Guard.
# Uma convenção de programação para a submissão de requisições de execução de seções críticas.

!!!T3 - Implementação II  [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]
* Estender o componente de sincronização apresentado em T2 para suportar também seções críticas síncronas. Para isso, serão utilizados ''futures'', cuja implementação será baseada em uma descrição apresentada em "Guarded sections: Structuring aid for wait-free synchronisation". G. Drescher and W. Schröder-Preikschat (2015) {DIV(type="span")}[{DIV}[#Refer_ncias_|2]].
* Modificar a convenção de programação para integrar os mecanismos de ''futures'', de modo a intermediar a comunicação entre threads e seções críticas bloqueantes.
__Entregável: D3__
# Componente Guarda com suporte a seções críticas síncronas.
# Novo mecanismo de ''futures''.

!!!T4 - Implementação III  [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]
* Aprimorar o modo como as seções críticas são definidas e permitir que sejam definidas seções críticas a partir de funções com um número arbitrário de parâmetros, assim como ocorre com threads.
* Substituir os mecanismos de sincronização das aplicações de teste pela nova implementação com uso de guarda.
__Entregável: D4__
# As aplicações ''synchronizer_test.cc'', ''scheduler_cpu_affinity_test.cc'' e ''semaphore_test.cc'' utilizando o algoritmo de guarda em vez de mutexes e semáforos.

!!!T5 - Validação  [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]
* Realização de testes em nível acadêmico, com o objetivo de garantir, na medida do possível, a corretude dos componentes implementados até aqui.
* Desenvolvimento de um relatório final, onde será apresentado o que foi feito durante o projeto e quais foram seus resultados.
__Entregável: D5__
# Relatório final, que é uma versão do relatório inicial com as correções de planejamento adicionadas ao longo da execução do projeto.
# O código dos novos testes realizados, junto com o resultado dos testes

!!!Tarefas Opcionais  [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]
# Uma segunda versão da implementação de Futures, com suporte completo requisições bloqueantes e não bloqueantes junto com um serviço de execução que trata de criar novas threads na medida que o sistema necessita executar códigos com dependência de dados. Ver a seção [#Futures_|Futures]. Tal serviço será reconfigurável, limitando o número máximo de threads que podem existir simultaneamente. Por exemplo, um sistema embarcado pode não possuir memória suficiente para que muitas thread sejam criadas, então esse serviço de threads limitaria o número máximo de threads que podem ser criadas ao mesmo tempo, e caso esse limite seja ultrapassado, novas requisições aguardam em uma fila, i.e., bloqueiam até que recursos estejam disponíveis. %%% Tal serviço também, pode ser configurado para iniciar com um número definido de threads que ficam aguardando um bloco de dependência ser requerido, e na medida que surge o diminui a demanda, vai criando e destruindo threads para economizar memória. Por preferência de performance e de não remover recursos do sistema, somente fazer tal balanceamento de carga quando uma idle thread entrar em execução. Assim, não se tira recursos de nenhuma outra thread em execução.
# A implementação da variação do algoritmo do __Guarda__ para arquiteturas NUMA {[https://en.wikipedia.org/wiki/Non-uniform_memory_access|2]}, o algoritmo do __Ator__. Ver a seção [#Atores_|Atores].

!!Fundamentação Teórica  [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]
Antigamente quando não existia poder computacional, não existia o conceito atual de threads por que não havia memória suficiente. Assim toda a programação de múltiplas tarefas deveria ser feita pelo programador manualmente, para poder-se extrair o máximo da máquina. Agora, hoje em dia com processadores com milhares de núcleos, volta a ter que se programar a máquina mais diretamente para poder garantir 100% (cem por cento) de throughput de todos os núcleos dos processadores.

O trabalho de referência {DIV(type="span")}[{DIV}[#Refer_ncias_|1]] propõe dois algoritmos de baixo nível, um para arquiteturas UMA {[https://en.wikipedia.org/wiki/Uniform_memory_access|1]}, outro para arquiteturas NUMA {[https://en.wikipedia.org/wiki/Non-uniform_memory_access|2]}, que permitem que o programador programe a iteração com a máquina, de forma que ele diga o que a máquina deve fazer, enquanto aguarda que suas seções críticas sejam executadas assincronamente. Regiões críticas assíncronas significam que threads podem requisitar a execução de arbitrárias regiões críticas, sem ter que bloquear a sua execução. Somente a região crítica terá sua execução adiada, devido a necessidade da exclusão mútua. Enquanto a região crítica aguarda sua execução em uma fila, a thread principal pode continuar sua execução. Em contraste, as tradicionais regiões críticas síncronas, exigem que a thread bloqueie a sua execução até que a região crítica seja executada.

Entretanto, note que o programador da aplicação deve tratar de isolar explicitamente em seu código quais são as suas regiões críticas com normalmente faz, e chamar/enviar essas regiões críticas para a fila da exclusão mútua dos algoritmo utilizado. A diferença é que elas não serão mais bloqueantes, assim o programador deve prever o que irá acontecer quando ele chegar em um ponto de execução de seu código, que é dependente dos resultados da execução da região crítica. Assim, no pior dos casos, a execução da thread terá que bloquear a execução, enquanto aguarda a chegada das novas informações provenientes da região crítica.

!!!Sincronização não bloqueante  [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]
Em ambientes multi thread, técnicas de sincronização precisam ser empregadas para coordenar o acesso à recursos compartilhados e evitar a ocorrência de problemas, como por exemplo, condições de corrida, que podem levar o sistema a se comportar de maneira indefinida ou errônea. No contexto da sincronização de threads, as partes do programa onde recursos compartilhados são acessados por diferentes threads são chamadas de seções críticas.

Técnicas tradicionais de sincronização utilizam mecanismos bloqueantes para coordenar a execução de seções críticas, impedindo que diferentes seções críticas executem simultaneamente e garantindo a propriedade de exclusão mútua. Nesses casos, quando uma thread tenta executar uma seção crítica, e os recursos compartilhados relacionados à essa seção crítica estão ocupados, a thread é bloqueada até que esses recursos sejam liberados. Esse comportamento simplifica a implementação de sistema concorrentes, mas pode levar a problemas de inversão de prioridade, tempos de espera indefinidos, convoying e até deadlocks.

Uma estratégia diferente para lidar com a sincronização de threads envolve a utilização de mecanismos e técnicas de sincronização não bloqueantes. Diferente do que ocorre com as técnicas tradicionais, no caso da sincronização não bloqueante, recursos compartilhados podem ser acessados concorrentemente por múltiplas threads sem a necessidade de bloqueio. Para isso, algoritmos não bloqueantes são cuidadosamente construídos com base em primitivas de sincronização atômicas do tipo ''read-write-modify'', geralmente implementadas em hardware, e podem ser utilizados para aumentar o nível de paralelismo do sistema.

Um nicho onde a sincronização não bloqueante se apresenta como uma alternativa viável é no mundo das aplicações para sistemas embarcados multicore. Como essas aplicações geralmente lidam diretamente com entidades físicas, elas se beneficiam de algumas das vantagens desse tipo de algoritmo, como suas garantias de progresso e a preditibilidade de latência de suas operações.

!!!Garantias de Progresso  [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]
Algoritmos de sincronização não bloqueantes podem ser classificados de acordo com as garantias de progresso de suas operações. Quando todas as operações de um determinado algoritmo oferecem garantias de progresso de um determinado nível, ou de níveis superiores, pode-se dizer esse é o nível de garantias de progresso oferecido pelo algoritmo como um todo. As garantias de progresso de operações de sincronização não bloqueantes são classificadas em três níveis:

*Obstruction-free: É a garantia de progresso de nível mais baixo. Uma operação é considerada obstruction-free se uma thread, executando de maneira isolada, sem sofrer interferências, i.e. competir com outras threads por recursos {[https://www.cs.rochester.edu/~scott/papers/2006_PPoPP_synch_queues.pdf|3] section 2.1}, consegue completar sua execução em um número finito de passos.

*Lock-free: Um operação é lock-free, se quando invocada por múltiplas threads, garante que pelo menos uma delas threads irá terminar em um número finito de passos. Dessa forma, operações lock-free nunca sofrem com problemas de deadlock e livelock {[https://softwareengineering.stackexchange.com/questions/141271/if-i-use-locks-can-my-algorithm-still-be-lock-free|4]}, pois pelo menos uma das threads executando a operação irá progredir. Implementações de soluções lock-free geralmente envolvem a utilização de laços, que geralmente envolvem a primitiva atômica CAS, onde threads repetem certos passos um número arbitrário de vezes, que depende da comportamento da operação, até conseguir prosseguir. Certos autores referem-se a algoritmos lock-free e algoritmos não bloqueantes de maneira análoga, o que pode gerar certa confusão, já que nem todo algoritmo não bloqueante é lock-free {[https://www.justsoftwaresolutions.co.uk/threading/non_blocking_lock_free_and_wait_free.html|5]}, pois podem também ser categorizados como wait-free ou obstruction-free.

* Wait-free: Uma operação é dita wait-free, se, quando invocada por múltiplas threads, garante que todas irão terminar em um número finito de passos. Essa propriedade é especialmente importante para sistemas com grande escala de concorrência, pois independentemente do número de threads executando operações wait-free concorrentemente, nenhuma jamais precisará esperar ou bloquear {DIV(type="span")}[{DIV}[#Refer_ncias_|13]], e como o progresso é garantido para todas as threads, nenhuma sofrerá com problemas de ''starvation''.

!!!Primitivas de Sincronização  [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]
A criação de algoritmos de sincronização não bloqueantes pode envolver a utilização de primitivas de sincronização atômicas do tipo ''read-write-modify''. Essas primitivas geralmente leem uma posição de memória e, simultaneamente, escrevem um novo valor em seu lugar. Exemplos de operações atômicas desse tipo são: compare-and-swap (CAS), fetch-and-operation (FAθ), load-link/store-conditional (LL/SC) e test-and-set (TAS). A seguir serão detalhadas duas dessas operações, CAS e FAS (fetch-and-store), uma especialização da operação FAθ. Ambas são utilizadas na implementação de um algoritmo de sincronização não bloqueante que será apresentado mais adiante.

A operação FAS realiza, de maneira atômica, uma leitura e uma escrita em um endereço de memória específico, e pode ser entendida como uma versão atômica do pseudocódigo, apresentado a seguir:
^::__Listagem 1:__ Pseudocódigo da implementação da operação FAS::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
int fas(address * location, int replacement) {
        int old = *location;
        *location = replacement;
        return old;
}
~/np~{DIV}
{DIV}^
A operação CAS, cuja implementação lógica em pseudocódigo pode ser vista abaixo, possui um funcionamento similar ao da operação FAS, no entanto, a escrita no endereço de memória sendo acessado ocorre de forma condicional, acontecendo apenas caso o resultado da comparação entre o valor atual desse endereço e o valor de uma determinada variável seja positivo. Na prática, a escrita só acontece caso o valor do endereço sendo acessado já é conhecido por quem está executando o CAS.
^::__Listagem 2:__ Pseudocódigo da implementação da operação CAS::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
int cas(address location, int compare, int replacement) {
    int old = *location;
    if(*location == compare) {
        *location = replacement;
    }
    return old;
}
~/np~{DIV}
{DIV}^
Um detalhe importante sobre essas operações é o fato de processadores geralmente não suportarem todos os tipos de primitivas ''read-write-modify'' em hardware. A arquitetura RISC-V, por exemplo, implementa apenas as operações FAθ e LL/SC, enquanto a arquitetura x86 não implementa a operação LL/SC, mas implementa a operação CAS.

!!!Sincronização Baseada em Delegação  [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]
Com algoritmos de sincronização baseados em delegação, threads podem delegar a execução de suas seções críticas à outras threads. Com isso, as seções críticas são desacopladas das threads que requisitam sua execução, que agora podem decidir se continuam trabalhando, sem bloquear, após delegar a execução de uma seção crítica, ou se preferem bloquear e continuar apenas após a execução da seção crítica terminar. Além disso, deve haver algum protocolo ou sistema de execução cujos mecanismos garantam que as seções críticas eventualmente serão executadas e que a propriedade da exclusão mútua será mantida.

Técnicas de sincronização baseadas em delegação podem definir uma única thread, geralmente presa a um core específico, como responsável pela execução das seções críticas do programa. Um dos benefícios dessa abordagem é o melhor aproveitamento da localidade de dados das caches do sistema, já que agora, todos os acessos aos dados das seções críticas são feitos pela mesma thread. Uma outra possível abordagem, permite que a responsabilidade de execução de seções críticas seja transferida entre threads de acordo com as necessidades do sistema. Nesse caso, diminui-se o aproveitamento da localidade das caches, mas remove-se a necessidade de se manter uma thread, ou até mesmo um core do processador, restrita a execução de seções críticas.

Em situações ideais, onde threads não precisam do resultado de suas seções críticas, ou seja, não existem dependências unilaterais de dados entre a seção crítica e a thread requisitando sua execução, o bloqueio dessas threads se torna opcional. Seções críticas que exibem essas características são chamadas de seções críticas assíncronas. Algoritmos de sincronização baseados em delegação para seções críticas assíncronas permitem que threads deleguem a execução de seções críticas utilizando mecanismos do tipo fire-and-forget, podendo continuar com sua própria execução e esquecer sobre a seção crítica cuja execução foi requisitada.

No entanto, isso nem sempre é possível e, em alguns casos, a sincronização baseada em delegação traz novos desafios. Caso existam dependências de dados entre uma seção crítica e a thread que requisitou sua execução, essa seção crítica é caracterizada como uma seção crítica síncrona. Com esse tipo de seção crítica, surge a necessidade de bloqueio da thread requerente, o que pode ocorrer no momento em que é feita a requisição de execução, ou apenas quando os dados que podem ainda não ter sido calculados, são acessados. No primeiro caso, podem ser utilizados mecanismos de bloqueio simples, como semáforos ou mutexes, enquanto no segundo, exige-se a utilização de mecanismos mais complexos, como ''futures'' e ''observables''.

!!Guardas  [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]
Todos os conceitos apresentados até aqui convergem em um algoritmo de sincronização, baseado em delegação, para seções críticas assíncronas, que dá origem a uma nova entidade de sincronização: a Guarda. Guardas possuem duas operações básicas, uma para a entrada e uma para a saída de seções críticas, vouch e clear, respectivamente, além de uma convenção de programação, apresentada na Listagem 1, que deve ser utilizada pelas threads do programa para requisitar a execução assíncrona de seções críticas.
^::__Listagem 3:__ Protocolo para a requisição de execução de seções críticas::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
Guard guard = ...; // Shared
...
Job * job = ...
Job * cur;
if (NULL != (cur = guard.vouch(job))) do {
    run(cur);
} while (NULL != (cur = guard.clear()));
~/np~{DIV}
{DIV}^
O algoritmo da guarda também introduz o conceito de uma entidade chamada ''sequencer'', que será responsável pela execução das seções críticas do programa. Toda thread, após emitir uma requisição de execução de seção crítica, pode ter que assumir o papel de ''sequencer''. Ao assumir esse papel, a thread deve trabalhar na execução de seções críticas até que não hajam mais requisições pendentes a serem executadas. A convenção de programação definida para submissão de requisições, junto com o modo de funcionamento das operações vouch e clear, impede que mais de um ''sequencer'' esteja ativo ao mesmo tempo, fazendo com que a execução das seções críticas ocorra de forma sequencial, garantindo a propriedade da exclusão mútua.

^::{img fileId="931"}::
::__Figura 1:__ Diagrama demonstrando o funcionamento do protocolo de submissão de seçẽos críticas::
::__Fonte:__: Própria::^

Em termos gerais, o funcionamento do protocolo de submissão de requisições de execução de seções críticas à guarda, que pode ser observado no diagrama da Figura 1, se dá da seguinte maneira: seguindo a convenção de programação estipulada, threads devem realizar um vouch para submeter requisições à guarda. Caso já exista um ''sequencer'' ativo, vouch retornará ''NULL'', sinalizando para a thread requerente que ela pode continuar com sua execução. No entanto, caso nenhuma thread esteja atuando como ''sequencer'', vouch retornará um job, sinalizando para a thread que ela deve atuar como ''sequencer'', começando pela execução do job retornado. Após terminar a execução desse job, a thread ''sequencer'' invoca a operação clear repetidamente, e enquanto houverem seções críticas à serem executadas, clear retornará novos jobs, que também serão executados pelo ''sequencer''. Quando não houverem mais seções críticas à serem executadas, clear retornará ''NULL'', sinalizando à thread que ela deve abandonar o papel de ''sequencer'' e continuar com sua execução normal.

^::{img fileId="933"}::
::__Figura 2:__ Atributos da guarda e de seus elementos::
::__Fonte:__: Própria::^

A partir da descrição geral do funcionamento do algoritmo, percebe-se que guardas comportam-se como filas, onde jobs representando seções críticas são armazenados. A Figura 2 representa a estrutura geral de uma guarda e de seus elementos, que correspondem a elementos de fila simples, com apenas um nível de encadeamento. Além de ser do tipo FIFO, como apenas o ''sequencer'' pode remover elementos, a fila representada pela guarda pode ser considerada uma fila multiple-producer-single-consumer (MPSC), pois, enquanto várias threads podem, simultaneamente, inserir elementos na guarda, apenas o ''sequencer'' pode removê-los. Essa característica diminui muito a complexidade de implementação de operações wait-free para a inserção e remoção de elementos, como poderá ser notado quando o código das operações vouch e clear for apresentado.

Uma implementação para vouch é apresentada na Listagem 2. Essa implementação utiliza as primitivas atômicas CAS e FAS, sinalizadas por V1 e V2 no código, para coordenar acessos a elementos da guarda compartilhados por múltiplas threads, de maneira a evitar a ocorrência de condições de corrida. Mais especificamente, FAS é utilizada, em V1, para coordenar a inserção de novos elementos na guarda por invocações distintas de vouch. Enquanto CAS é utilizada, em V2, para lidar com o caso especial onde a guarda possui apenas um elemento, que pode ser acessado simultaneamente por vouch e clear, e, portanto, deve ser acessado de maneira coordenada.
^::__Listagem 4:__ Implementação da operação vouch::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
Element * vouch (Element * item) {
    item->next = NULL ;
    Element * last = FAS(_tail, item ); // V1
    if (last && CAS (last->_next, NULL, item )) // V2
        return NULL ;
    _head = item ; // V3
    return item ;
}
~/np~{DIV}
{DIV}^
A operação clear é responsável por remover elementos da guarda. Implementações wait-free de operações de remoção de elementos de estruturas de dados tendem a ser extremamentes complexas, no entanto, como destacado previamente, o comportamento MPSC da guarda acaba simplificando muito o código de clear, apresentado na Listagem 3. Assim como no caso de vouch, as operações FAS e CAS são utilizadas para garantir que invocações simultâneas de clear por múltiplas threads nunca resultem em condições de corrida. No trecho de código sinalizado por C1 na Listagem 3, a operação FAS é utilizada para coordenar a definição de qual elemento deve ser a próxima cabeça da guarda, cujo valor é armazenado na variável next, além disso, FAS também marca, simultaneamente, next->_next com o valor mágico DONE, utilizado para controlar a interação entre execuções simultâneas de  vouch e clear, onde pode haver a necessidade de uma transição de ''sequencer''. Caso a variável next tenha recebido o valor ''NULL'', tem-se que a lista possui menos de um elemento, e a semântica de clear indica que não apenas a cabeça da lista deve ser modificada mas também a sua cauda, nesse caso, ambas modificações afetam o mesmo elemento e precisam ser coordenadas, por isso são implementadas por operações CAS.

As implementações de vouch e clear apresentadas são wait-free, pois permitem a invocação dessas operações por múltiplas threads com garantias de progresso para cada uma delas. Dessa forma, caso já exista um ''sequencer'' ativo, o progresso wait-free de todas as threads que submeterem requisições à guarda é garantido, pois esse processo envolve apenas uma invocação à vouch, que também é wait-free. No entanto, as garantias de progresso se tornam mais complexas para o caso de threads que precisam assumir o papel de ''sequencer''. Em sistemas onde threads submetem seções críticas à guarda com muita frequência, uma thread que assume o papel de ''sequencer'' pode ter que executar seções críticas indefinidamente, o que a impedirá de progredir com o resto do seu código. Além disso, seções críticas maliciosas, que executam indefinidamente, também podem impedir o progresso do ''sequencer''. No entanto, esse tipo de seção crítica nunca deve existir, e sua presença pode ser considerada um erro de programação.
^::__Listagem 5:__ Implementação da operação clear::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
Element * clear() {
    Element * item = _head;
    Element * next = FAS(item->_next, DONE); // C1
    if (!next)
        CAS(_tail , item, NULL); // C2
    CAS(_head, item, next);  // C3
    return next ;
}
~/np~{DIV}
{DIV}^
Até agora, o algoritmo tratou apenas de seções críticas assíncronas, onde o código das threads não depende de dados calculados nas seções críticas, mas esse nem sempre é o caso. Dessa forma, o algoritmo da guarda pode ser estendido para lidar também com seções críticas síncronas. Para isso, são adicionados mecanismos como ''futures'' {DIV(type="span")}[{DIV}[#Refer_ncias_|14]], que permitem a comunicação de dados entre threads e suas seções críticas, de modo a satisfazer dependências unilaterais de dados.

Além dos problemas já citados, várias considerações podem ser feitas em relação à threads de prioridades diferentes compartilhando uma mesma guarda. Nesses casos, inversões de prioridade podem acontecer nos casos onde threads de alta prioridade se tornam ''sequencer'' e são forçadas a executar seções críticas de threads de baixa prioridade, ou em casos onde seções críticas relacionadas à threads de alta prioridade são executadas por threads de baixa prioridade. Para solucionar esses problemas, podem ser desenvolvidas variações do algoritmo, onde o papel de ''sequencer'' pode ser renegociado para que as definições de prioridade do sistema sejam respeitadas.

!!!Atores  [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]
Existe uma variação do algoritmo da guarda, chamado de algoritmo dos atores, onde a execução das seções críticas é realizada por uma thread servidora dedicada. Em aspectos funcionais, os dois algoritmos são muito parecidos. Ambos possuem duas operações principais, uma para a inserção e uma para a remoção de seções críticas de filas, e uma convenção de programação que deve ser utilizada pelas threads do programa para delegar a execução de suas seções críticas.

Algoritmos de sincronização baseados em delegação onde uma única thread dedicada é responsável pela execução de seções críticas aproveitam ao máximo a localidade no acesso à dados compartilhados, mas pagam um preço por restringirem uma thread, ou até mesmo um core do processador, apenas à execução de seções críticas. Devido a essas característica, o algoritmo dos atores tende a se comportar melhor em sistemas com muitos núcleos de processamento (many-core).

Outro detalhe a ser considerado com esse tipo de abordagem é o overhead decorrente da necessidade da thread dedicada ser posta para dormir quando não existem seções críticas à serem executadas.

!!!Comparação entre o uso do guarda e semáforo  [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]
Uma versão equivalente ao uso de guardas, pode ser implementada utilizando várias threads e um semáforo inicializado em 1 para controle da entrada da seção crítica, i.e., exclusão mútua. Na implementação apresentada para o algoritmo de guardas, utiliza-se um ponteiro de função para passar para o ''sequencer'', qual será a seção crítica a ser executada. Enquanto, na versão com threads, teria-se que criar uma nova thread, além da thread atual, passando um ponteiro de função para a seção crítica. E então essa nova thread irá testar o valor do semáforo antes de executar a seção crítica.

A seguir, vê-se resumidamente o fluxo de execução do algoritmo do guarda, já explicado anteriormente. Nele, a ''Thread A'' primeiro empilha um ponteiro de função __job__ na fila de tarefas da variável global __my_guard__ e então verifica se a ''Thread A'', deve ou não se tornar o ''sequencer''. Como a ''Thread A'' é a primeira thread a empilhar uma região crítica, __guard_vouch()__ retorna um valor não nulo, indicando a próxima tarefa a ser executada. Assim, a ''Thread A'' torna-se o ''sequencer''. E logo em seguida, chama o método __do_things()__ que executa a função que contém a região crítica representado por __next_job__. No final da execução, a ''Thread A'' chamará __guard_clear()__, que neste ambiente de exemplo retornará ''NULL'', pois não há outras threads/seções críticas.
^::{img fileId="943"}::
::__Figura 3:__ Resumo do algoritmo do Guarda::
::__Fonte:__ Própria::^

Agora, vê-se um equivalente do mesmo exemplo do guarda, mas utilizando um semáforo global inicializado em 1 para todas as threads, pois para garantir exclusão mútua somente pode existir uma thread executando a região crítica. Primeiro, cria-se uma thread com new, passando como parâmetro um __semáforo__ compartilhado e um ponteiro de função __job__. É importante notar que não se faz __join()__ nesta thread, pois se está tratando de uma seção crítica assíncrona, e precisa-se também de uma implementação especial de thread que antes de chamar o ponteiro de função de __job__, dê um ''lock()'' no semáforo, e depois de completar a função, delete a si própria. Comparando este novo código com o algoritmo do guarda, vê-se que ele ficou muito mais simples, entretanto, perde-se muito na eficiência pois para executar uma seção crítica assincronamente, tem-se que criar exclusivamente uma nova thread para cada uma das threads já existentes, tendo a criação do dobro de threads no sistema em um momento de alta competição pela seção crítica.
^::{img fileId="946"}::
::__Figura 4:__ Resumo do funcionamento de um semáforo, equivalente ao algoritmo do Guarda::
::__Fonte:__ Própria::^

O leitor mais atento pode perceber que, abordou-se somente uma implementação sem dependência de dados com a seção crítica e, que a versão do algoritmo do guarda apresentado neste exemplo também não executou assincronamente. Somente a segunda versão, que utiliza um semáforo fez uma execução assíncrona da seção crítica. Este é um dos problemas do algoritmo do guarda. A thread que for eleita como ''sequencer'', será impedida de executar sua seção crítica assincronamente, pois ela própria tem que executar a sua seção crítica mais as seções críticas das outras threads que empilharem seus __jobs__. Com isso, pode-se ter como já falado anteriormente, o problema de ''starvation'' do ''sequencer'', que pode infinitamente continuar recebendo novos __jobs__ para executar. Entretanto, ter-se somente uma thread exclusivamente executando todas as seções críticas, traz-se a vantagem de localidade da cache caso o ''sequencer'' execute sempre em um mesmo núcleo do processador.

Outro problema que tanto a versão com semáforo quanto a versão com guardas apresentam, é quando a seção crítica é uma função recursiva. No caso do semáforo, o sistema entrará em deadlock durante a primeira recursão, pois devido a exclusão mútua que o algoritmos possuem, somente existe uma função executando a seção crítica ao mesmo tempo, e o deadlock será imediato ao início da chamada recursiva. A diferença é que o deadlock, não impede o progresso das regiões não críticas do sistema, por que por exemplo, na segunda vez que for chamado __guard_vouch()__, ele irá empilhar um ponteiro de função __job__ que irá esperar para sempre, mas o ''sequencer'' continuará executando o resto do programa que vem depois da seção crítica, pois este é o comportamento do guarda quando já existem __jobs__ na seção crítica.

Este foi um exemplo de problema tanto do algoritmo do guarda quando com semáforos, onde uma região crítica pode impedir que seções críticas sejam executadas, mas permitir que as regiões não críticas continuem executando. Note que isso pode causar falta de memória no sistema pois, toda que uma seção crítica tentar ser executada, mais um ponteiro de função (ou thread no caso do semáforo) será empilhado na fila de execução do ''sequencer'', que ficará eternamente como ''sequencer'' sem executar mais nenhuma linha de código de seções críticas.

Outro problema muito similar do algoritmo do guarda, é que quando a seção crítica é explicitamente  bloqueada por algum motivo, seja uma operação de IO ou seja por que ela possuía um semáforo que bloqueou. Bloqueios dentro da seção crítica no algoritmo do guarda, causarão diretamente a degradação/atraso da execução de todas as seções críticas do sistema, pois é somente a thread do ''sequencer'' que é habilitado a executar as seções críticas. Note também que na versão assíncrona implementada com semáforo, terá-se a possibilidade de travar todo o sistema caso aconteça o mesmo problema, pois mesmo que cada thread execute isoladamente, atrasos na execução de uma seção crítica, atrasam a liberação do semáforo, o que causa o atraso no sistema como um todo.

!!!Futures  [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]
Seguindo as referências bibliográficas, encontrou-se que ''futures'' foram descritas pela primeira vez em 1977 no artigo "The incremental garbage collection of processes”. ''Futures'' facilitam a resolução do problema de bloqueio por dependência de dados. No diagrama de sequência a seguir, como implementar o bloqueio no ''bloco 4'' e sinalizar para o ''bloco 4'' que o ''bloco 2'' já terminou, enquanto o ''bloco 3'' executa?
^::{img fileId="969"}::
::__Figura 5:__ Exemplo de dependência de dados com a seção crítica::
::__Fonte:__ Própria::^

O ''bloco 4'' somente pode ser executado quando a sessão crítica no ''bloco 2'' já tiver sido executada. Uma vez que o fluxo de execução chega nesse ponto, a ''Thread 1'' deve bloquear caso o ''bloco 2'' ainda não tenha sido executado pelo ''sequencer''. Isso não seria um problema para o trabalho por que quando existe dependência de dados, o código que é dependente fica encapsulado em uma __closure__ {DIV(type="span")}[{DIV}[#Refer_ncias_|12]] que é chamada quando o resultado do __bloco 2__ fica pronto. A seguir ve-se o fluxo de execução desse caso com o uso de ''futures'':
^::{img fileId="950"}::
::__Figura 6:__ Exemplo de dependência de dados com a seção críticas utilizando ''Future''::
::__Fonte:__ Própria::^

Nessa nova versão com ''futures'' vê-se um novo problema não abordado pelo artigo de referência {DIV(type="span")}[{DIV}[#Refer_ncias_|1]]. Nesse fluxo de execução, quem deve executar o ''bloco 4''? A ''Thread A'' não pode mais executar este bloco porque ele foi condicionado a ser executado depois do ''bloco 2'', que é executado assíncronamente pelo ''sequencer''. Entretanto, não pode-se deixar que o ''sequencer'' execute o ''bloco 4'' por que o ''sequencer'' somente é encarregado de executar as seções críticas, e permitir que ele execute outros blocos não críticos, irá atrasar toda pipeline de execução de seções críticas.

Isso trás uma alternativa implementação de ''futures'' que o artigo {DIV(type="span")}[{DIV}[#Refer_ncias_|1]] sugere, onde cada ''future'' possui um semáforo acoplado, e a execução do ''bloco 4'' não é delegada ao ''sequencer'', mas sim a ''Thread A'' que irá bloquear automaticamente quando o fluxo de execução chegar ao ''bloco 4'' e o resultado do ''bloco 2'' ainda não estiver disponível. Caso o resultado do ''bloco 2'' já esteja disponível, a ''Thread A'' não irá bloquear e seguirá executando o ''bloco 4''. Infelizmente, pode-se não querer o programa bloqueie quando existe a dependência de dados explicita como essa alternativa sugere.

Por isso, a seguir vê-se um diagrama de sequência sobre a implementação de ''future'' descrita no artigo {DIV(type="span")}[{DIV}[#Refer_ncias_|14]] inicial de 1977. Este artigo descreve que, além das tradicionais ''chamadas-por-valor'' e ''chamadas-por-referência'', também existem as ''chamadas-por-future'', onde cada parâmetro da função é ligado a um processo separado (chamado ''future''). Este processo é dedicado a calcular o valor do argumento que a ''future'' representa, o que completamente permite a execução paralela dos argumentos da função, assim aumentado o poder expressivo da linguagem de programação.
^::{img fileId="968"}::
::__Figura 7:__ Exemplo de dependência de dados com um ''Future Thread''::
::__Fonte:__ Própria::^

No exemplo anterior, foi simplificado funcionamento do algoritmo do guarda e abstraiu-se quem é o ''sequencer'' fazendo com que a entidade que representa tipo __Guarda__, chame o método ''do_things()'' como se ele fosse o ''sequencer''. A versão estritamente correta da implementação seria fazer com que uma thread como ''Thread A'' fosse o ''sequencer'', e então  a ''Thread A'' deveria fazer a chamada de ''do_things()''. Além dessa simplificação, assume-se que a implementação de Thread utilizada não inicia a execução imediatamente após sua criação. Ela espera até que o método __start()__ seja chamado, e que a thread permita a execução de vários funções, uma após a outra. As funções que esta thread precisa executar são adicionadas através do método ''append()''.

Os eventos que acontecem no diagrama de sequência são os seguintes, primeiro a ''Thread A'' executa um bloco de código não crítico. Depois ela cria uma ''Future'' com um __job__ que é um ponteiro de função para o ''bloco 2''. O método ''then()'' da variável ''future'' é utilizada para adicionar os blocos de código que são dependentes da seção crítica no ''bloco 2''. Os resultados da execução da seção crítica no ''bloco 2'' são passado em diante para o ''bloco 4'' como parâmetros que o ponteiro de função de entrada do ''bloco 4'' aceita.

Depois de criada a ''future'', a ''Thread A'' chama o método ''guard_vouch()'' passando a ''future'' como parâmetro. Então o algoritmo do guarda segue o fluxo da sua execução como já explicado na seção Guarda. Por simplicidade, assumi-se que depois que o método ''guard_vouch()'' retornou, a ''Thread A'' não assumiu o papel do ''sequencer'', mas que a entidade Guarda do diagrama de sequência é o atual ''sequencer'' em execução, e que já de imediato o ''sequencer'' chamou o método ''do_things()'' da ''future''. Uma vez que o método ''do_things()'' completou sua execução, o ''sequencer'' para de executar o ''bloco 2'', e chama o método ''jobs_list->start()'' que chamada a ''Future Thread'' para realizar a execução dos blocos dependentes da seção crítica. Uma vez que isso acontece, o ''sequencer'' inicia a execução de uma outra seção crítica, que foi omitida no diagrama. Assim, permiti-se que o ''sequencer'' exclusivamente execute seções críticas, enquanto a ''Future Thread'' executa os blocos dependentes da seção crítica, assincronamente, junto com a execução do ''bloco 3'' da ''Thread A''.

Claramente esta implementação mostrada é simples, e trata-se de uma leve modificação da versão original {DIV(type="span")}[{DIV}[#Refer_ncias_|14]]. Seu defeito é sempre realizar a criação de uma nova thread para cada variável ''Future'', pois assim tem-se a criação de muitas threads no sistema, já que sempre cria-se uma thread nova depois que adiciona-se o primeiro bloco com dependência de dados. A implementação inicial {DIV(type="span")}[{DIV}[#Refer_ncias_|14]] dispõe de um serviço de execução que trata de criar novas threads na medida que o sistema necessita. Por exemplo, um sistema embarcado pode não possuir memória suficiente para que muitas thread sejam criadas, então esse serviço de threads limitaria o número máximo de threads que podem ser criadas ao mesmo tempo, e caso esse limite seja ultrapassado, novas requisições aguardam em uma fila, i.e., bloqueiam até que recursos estejam disponíveis para a execução das seções de código dependentes da seção crítica

Um serviço/implementação mais avançado pode automaticamente informar a ''Thread A'' que, existe um bloco de código dependente da seção crítica ainda não executado, e assim, antes que a ''Thread A'' termine sua execução, ela verifica se tal condição é verdadeira, e caso, sim, ela aguarda por este bloco está disponível para execução antes de chamar método ''exit()'' da ''Thread A''. Uma desvantagem é que a ''Thread A'' pode ainda não ter terminado de executar o ''bloco 3'' quando o bloco dependente da seção crítica estiver terminado. Assim, teria-se o atraso da execução do ''bloco 4''. Outra  desvantagem desta alternativa é que o bloco de código dependente pode demorar muito tempo antes que ele possa ser executado, e assim, o sistema desperdiçaria a memória ocupada pela ''Thread A'' que ficou esperando. Assim, a alternativa original de manter um serviço especializado de threads em executar os blocos de código dependentes trás uma melhor vantagem de economia de memória, entretanto ele conta com o overhead de sua manutenção, que conta com criações de novas thread quando a demanda for alta e destruição de threads quando a demanda por blocos dependentes de código for baixa. Mas talvez em uma implementação mais esperta pode-se utilizar a idle thread {DIV(type="span")}[{DIV}[#Refer_ncias_|21]] do sistema para realizar a manutenção de tal serviço, assim reaproveitando recursos do sistema inutilizados.
%%%
!!!!Futures versus Promises  [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]
A linguagem JavaScript recentemente em 2015, incorporou nativamente a classe ''Promise'' {[https://www.ecma-international.org/ecma-262/6.0/#sec-promise-objects|6]}. Conceitualmente elas são muito similares a ''futures'' {DIV(type="span")}[{DIV}[#Refer_ncias_|14]], mas a implementação de JavaScript é bastante peculiar ao modelo de processamento de JavaScript, que é baseado na existência de uma única thread no sistema {DIV(type="span")}[{DIV}[#Refer_ncias_|16], [#Refer_ncias_|18]]. A seguir vê-se uma breve ilustração da única thread que existe no mundo JavaScript. Essa thread chama-se ''Event loop'', e tudo o que é feito, passa por ela. No caso da implementação das ''promises'', quando uma ''promise'' é resolvida e obtém o seu valor, elas furam {DIV(type="span")}[{DIV}[#Refer_ncias_|16]] a fila de ''callbacks'', para assim serem executadas o mais brevemente possível, preferencialmente mais cedo, ao contrário do modelo usual utilizado para timers, de executar algum tempo depois que o timer expirou, preferencialmente mais tarde pois são adicionados no final da fila.
^::{img fileId="945"}::
::__Figura 8:__ Ilustração do funcionamento programa JavaScript::
::__Fonte:__ Referência {DIV(type="span")}[{DIV}[#Refer_ncias_|16]]::^

Assim, ''promises'' em JavaScript funcionam não para fazer computações pesadas, mas sim esperar por eventos assíncronos e que podem demorar muito tempo para acontecer, como por exemplo, esperar pela resposta de uma requisição de rede. A seguir vê-se um exemplo do uso de uma ''promise'' que executa assincronamente. Em JavaScript como somente existe uma thread, então tudo o que se executa é sequencialmente {[https://benjaminhorn.io/code/part-2-cpu-intensive-javascript-computations-without-blocking-the-single-thread/|7]}. Na execução de ''promises'' em JavaScript, refere-se assincronamente para dizer que ao se executar este trecho de código, ele não irá bloquear, e somente algum momento mais tarde (assíncrono, fora de sincronia), a soma será realizada, e novamente sem bloquear a execução da única thread que existe, o ''Event loop''.
^::__Listagem 6:__ Implementação de uma Promise ja<x>vascript::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
function sum(xPromise, yPromise) {
    return Promise.all([xPromise, yPromise])
    .then(function(values) {
        return values[0] + values[1];
    } );
}

sum(fetchX(), fetchY())
.then(function(sum) {
    console.log(sum);
});
~/np~{DIV}
::__Fonte:__ Referência {DIV(type="span")}[{DIV}[#Refer_ncias_|16]]::
{DIV}^

Assuma de os método ''fetchX()'' e ''fetchY()'' returnam alguma ''promise'' depois de fazerem alguma computação. A função ''sum()'' mostrada anteriormente, recebe duas ''promises'' como parâmetro, e chama o método estático ''Primise.all()'', que recebe um array de ''promises'' e retorna uma nova ''promise'' que irá chamar o seu correspondente ''callback'' indicado por ''then()'', assim que todas as suas "''sub-promises''” forem resolvidas, i.e., efetivamente conterem um valor ao invés de somente serem uma promessa de conter algum valor.

Diferente de JavaScript, em C++ e outras linguagens como Java, existem as implementações dos tipos ''Futures'' e ''Promises''. A biblioteca ''std'' do C++ defines as classes template ''std{DIV(type="span")}:{DIV}:promise'' {[https://en.cppreference.com/w/cpp/thread/promise|8]} e ''std{DIV(type="span")}:{DIV}:future'' {[https://en.cppreference.com/w/cpp/thread/future|9]}. A funcionalidade empregada a esses tipos são a transmissão de resultados da computação de uma thread para outra thread que aguarda os resultados. De maneira tradicional, para receber um valor de uma thread precisa-se compartilhar uma variável de condição e um ponteiro comuns a ambas as threads. Uma vez que a outra thread obtém o valor e coloca o mesmo no ponteiro compartilhado, pede-se para a variável de condição liberar a passagem. Então a outra thread que aguardava o resultado desbloqueia e pode seguir com a execução. A desvantagem dessa abordagem é a necessidade de manter e operar diretamente a variável de condição e o ponteiro, e caso queira-se compartilhar mais resultados entre as diferentes threads, a programação fica ainda mais complicada pois precisa-se manter sincronia com mais variáveis de condição. Já com ''std{DIV(type="span")}:{DIV}:promise'' e ''std{DIV(type="span")}:{DIV}:promise'', pode-se abstrair essas operações repetitivas e simplificar a programação. A seguir vê-se um exemplo de utilização destas classes para compartilhamento de dados entre duas threads:
^::{img fileId="947"}::
::__Figura 9:__ Resumo do funcionamento entre os tipos ''Future'' e ''Promise'' em C++::
::__Fonte:__ Referência {DIV(type="span")}[{DIV}[#Refer_ncias_|17]]::^

No exemplo anterior, tem-se a ''Thread 1'' criando um objeto do tipo ''std{DIV(type="span")}:{DIV}:promise'', então solicitando que o objeto ''std{DIV(type="span")}:{DIV}:promise'' retorne seu objeto do tipo ''std{DIV(type="span")}:{DIV}:future''. Em seguida, cria-se a ''Thread 2'' passando o objeto ''std{DIV(type="span")}:{DIV}:promise''. Uma vez que a ''Thread 1'' tentar acessar o valor dentro de seu objeto ''std{DIV(type="span")}:{DIV}:future'', ela irá bloquear automaticamente caso esse resultado ainda não tenha sido colocado dentro do ''std{DIV(type="span")}:{DIV}:future'' através de seu objeto ''std{DIV(type="span")}:{DIV}:promise'' correspondente. A seguir vê-se um exemplo de código em C++ que segue o padrão descrito no diagrama anterior:
^::__Listagem 7:__ Implementação de uma Promise C++::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
#include <iostream>
#include <thread>
#include <future>

void initiazer(std::promise<int> * promiseObject)
{
    std::cout << "Inside Thread" << std::endl;
    promiseObject->set_value(35);
}

int main()
{
    std::promise<int> promiseObj;
    std::future<int> futureObject = promiseObj.get_future();
    std::thread thread(initiazer, &promiseObj);
    std::cout << futureObject.get() << std::endl;
    thread.join();
    return 0;
}
~/np~{DIV}
::__Fonte:__ Referência {DIV(type="span")}[{DIV}[#Refer_ncias_|17]]::
{DIV}^
%%%
!!!!Futures versus Observables  [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]
Não há muito o que dizer sobre a diferença entre ''futures'' {DIV(type="span")}[{DIV}[#Refer_ncias_|14]] e ''observables'' {DIV(type="span")}[{DIV}[#Refer_ncias_|20]]. Cada um deles servem a propósitos bem específicos, entretanto o domínio de soluções de problemas entre ''futures'' e ''observables'' possuí uma intersecção válida quando não utiliza-se ''futures'' que realizam o bloqueio da thread, mas sim ''futures'' que registram uma lista de blocos de execução dependentes para serem chamados assim que o resultado da future estiver completo. Neste contexto, a versão equivalente para ''observables'' seria registrar a lista de blocos dependentes do resultado como observadores.

A desvantagem de utilizar ''observables'' no lugar de uma ''futures'' seria o encadeamento manual de ''observables'' necessário para cada um dos blocos de dados da cadeia. A desvantagem de utilizar ''futures'' no lugar de ''observables'' seria a impossibilidade de registrar vários blocos como dependentes do mesmo resultado, pois ''observables'' permitem que vários ouvintes sejam registrados e que estes ouvinte seja chamados várias vezes, i.e., a cada vez que um novo resultado é produzido. Enquanto ''futures'' chamam seu ouvinte uma única vez para um único resultado gerado.

!!!Diagrama das Estruturas de Dados Originais  [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]
Para o funcionamento do algoritmo {DIV(type="span")}[{DIV}[#Refer_ncias_|1]], utiliza-se algumas estruturas de dados em "C”. A seguir vê-se as relações entre elas:
^::{img fileId="908"}::
::__Figura 10:__ Diagrama de classes do tipos de dados do algoritmo do Guarda::
::__Fonte:__ Própria::^

^::__Listagem 8:__ Estruturas de dados em C::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
typedef struct
{
    chain_t* next;
} chain_t;

typedef struct
{
    chain_t* head;
    chain_t* tail;
} guard_t;

typedef struct
{
    chain_t* head;
    chain_t* tail;
    sleep_t wait;
} actor_t;
~/np~{DIV}
{DIV}^

!!!Diagrama de Sequência - Versão original em C  [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]
Exemplo do fluxo de execução de uma única Thread que se torna o ''sequencer'', e executa sua seção crítica:
^::{img fileId="949"}::
::__Figura 11:__ Exemplo detalhado da execução do algoritmo do Guarda em ''C''::
::__Fonte:__ Própria::^

A seguir vê-se a implementação do algoritmo do guarda, como apresentado no artigo {DIV(type="span")}[{DIV}[#Refer_ncias_|1]], utilizando a linguagem "C".
^::__Listagem 9:__ Implementação do algoritmo do Guarda em C::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
void guard_setup(guard_t* self)
{
    self->head = self->tail = NULL;
}

chain_t* guard_vouch(guard_t* self, chain_t* item)
{
    item->next = NULL;
    chain_t* last = FAS(&self->tail, item); // V1
    if (last)
    {
        if (CAS(&last->next, NULL, item)) // V2
            return NULL;
        // last->next == DONE
    }
    self->head = item; // V3
    return item;
}

chain_t* guard_clear(guard_t* self)
{
    chain_t* item = self->head; // C1
    // item != NULL
    chain_t* next = FAS(&item->next, DONE); // C2
    if (!next)
        CAS(&self->tail, item, NULL); // C3
    CAS(&self->head, item, next); // C4
    return next;
}
~/np~{DIV}
{DIV}^

!!Análise de viabilidade  [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]
No EPOS x86 não hà uma implementação para a operação FAS, uma das duas primitivas atômicas utilizadas no algoritmo das guards. Uma possível implementação para essa operação é apresentada a seguir:
^::__Listagem 10:__ Implementação da operação de FAS::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
template<typename T>
static T fas(volatile T & value, volatile T replacement) {
    ASM("lock xchg %0, %2" : "=a"(replacement) : "a"(replacement), "m"(value) : "memory");
    return replacement;
}
~/np~{DIV}
{DIV}^
Mesmo que não consiga-se realizar uma implementação correta para ''FAS()'', pode-se implementar a FAS utilizando CAS. Por exemplo, uma chamada FAS seria ''FAS(entrada, saída)'' e a versão com CAS equivalente seria ''CAS(entrada, entrada, saída)''. Assim, a diferença seria que utilizar um CAS pode ser menos eficiente ao invés de utilizar somente um ''FAS()'' implementado em assembly.

Como ARM não suporta CAS, apenas LC/SC, pretende-se limitar a implementação do algoritmo apenas à versão do EPOS para a arquitetura x86.

A seguir vê-se um simples programa que utiliza a operação ''CAS()'' atualmente implementada no EPOS.
^::__Listagem 11:__ Arquivo ''/app/cas_test.cc''::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
// EPOS CAS Component Test Program

#include <utility/ostream.h>
#include <architecture/ia32/cpu.h>

using namespace EPOS;
OStream cout;

int main()
{
    cout << endl << "Welcome to the CPU::cas() instruction test!" << endl;
    int original = 5;
    int compare = 5;
    int replacement = 6;
    int replaced;

    cout << "original=" << original
            << ", compare=" << compare
            << ", replacement=" << replacement
            << ", replaced=" << replaced
            << endl;

    replaced = CPU::cas(original, compare, replacement);

    cout << "original=" << original
            << ", compare=" << compare
            << ", replacement=" << replacement
            << ", replaced=" << replaced
            << endl;

    cout << "The CPU::cas() instruction set ran successfully!" << endl << endl;
}
~/np~{DIV}
{DIV}^
Resultado da execução:
^::__Listagem 12:__ Arquivo ''/app/cas_test.cc''::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
Welcome to the CPU::cas() instruction test!
original=5, compare=5, replacement=6, replaced=0
original=6, compare=5, replacement=6, replaced=5
The CPU::cas() instruction set ran successfully!

The last thread has exited!
Rebooting the machine ...
~/np~{DIV}
{DIV}^

!!Implementação  [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]
Código disponível em svn:
# https://github.com/evandrocoan/predictable_synchronisation_algorithms_for_asynchronous_critical_sections
# https://epos.lisha.ufsc.br/svn/makers/predictable_synchronisation_algorithms_for_asynchronous_critical_sections
Para a implementação do algoritmo das guardas no EPOS foram definidas três novas classes, que representam as principais abstrações envolvidas na versão básica do algoritmo, seções críticas, elementos de guarda e a guarda em si. Essas classes encapsulam toda a lógica do algoritmo e fornecem interfaces para a delegação da execução de seções críticas por threads arbitrárias.

Neste capítulo será descrito como ocorreu o processo de implementação das novas classes que implementam o algoritmo das guardas, assim como os testes realizados para validação da implementação.

!!!Critical_Section [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]
Assim como ocorre com os algoritmos de sincronização tradicionais, uma das bases dos algoritmos de sincronização baseados em delegação é o conceito de seções críticas. Dessa forma, foi definida uma nova classe para representar essas entidades.

A classe que representa seções críticas  foi criada com base na classe Function_Handler e recebeu o nome de ''Critical_Section''. Essa classe possui apenas dois atributos, _handler e _link. O atributo _handler representa a função relacionada à seção crítica e o atributo _link representa um elemento de lista simples. Além desses dois atributos, a classe ''Critical_Section'' também implementa o método público run(), que é utilizado pelo sequencer para executar uma seção crítica, que na verdade é o mesmo trabalho realizado pelo operator “()”, que deixava o código pouco intuitivo. A Listagem 5 exibe o código da classe ''Critical_Section''.

O construtor da classe ''Critical_Section'' recebe um objeto representando uma função, que deve ser compatível com o tipo Function, definido no arquivo ''handler.h'', como parâmetro. Além disso, o construtor cria o _link relativo à seção crítica sendo construída, que será utilizado para adição e remoção de seções críticas de estruturas de dados, da mesma forma como acontece com objetos da classe Thread.
^::__Listagem 13:__ Seção crítica::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
class Critical_Section
{
public:
    friend class Guard;
    typedef Handler::Function Function;
    typedef List_Elements::Singly_Linked<Critical_Section> Element;

public:
    Critical_Section(Function * h): _handler(h), _link(this) {}
    ~Critical_Section() {}

    void operator()() { _handler(); }
    void run()        { _handler(); } // Alias for ()

private:
    Function * _handler;
    Element _link; // Inspired by the thread code
};
~/np~{DIV}
{DIV}^
Exemplos da utilização da classe ''Critical_Section'' durante a submissão de seções críticas à guarda estão na seção sobre os testes realizados.

!!!Element [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]
Como elementos da guarda são elementos de lista simples, com apenas um nível de encadeamento, optou-se por utilizar a classe List_Elements::Singly_Linked, Listagem 6, definida no arquivo ''list.h'', para representá-los.

No entanto, foi necessário adicionar uma relação de amizade entre a classe Singly_Linked e a classe Guard, para que as operações CAS e FAS dos métodos vouch e clear da classe guardam possam acessar diretamente o atributo _next do elemento de lista. Isso porque, não é possível efetuar as operações CAS e FAS utilizando getters.
^::__Listagem 14:__ Link contendo a seção crítica::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
// Simple List Element
template<typename T>
class Singly_Linked
{
public:
    friend class _UTIL::Guard;
    typedef T Object_Type;
    typedef Singly_Linked Element;

public:
    Singly_Linked(const T * o): _object(o), _next(0) {}

    T * object() const { return const_cast<T *>(_object); }

    Element * next() const { return _next; }
    void next(Element * e) { _next = e; }

private:
    const T * _object;
    Element * _next;
};
~/np~{DIV}
{DIV}^

!!!Guarda [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]
O código onde da classe Guard, definida no arquivo ''utility/guard.h'', é mostrado na Listagem 7. Essa classe implementa a estrutura da guarda descrita no capítulo de fundamentação teórica.
^::__Listagem 15:__ Definição da interface do Guarda::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
class Guard
{
public:
   typedef Closure::Element Element;

private:
   static const int NULL = 0;
   static const int DONE = 1;

public:
   Guard();
   ~Guard();

   void submit(Closure * cs);
   Element * vouch(Element * item);
   Element * clear();

private:
   Element * _head;
   Element * _tail;
};
~/np~{DIV}
{DIV}^
Além das operações vouch, clear e a operação de criação da guarda (setup), já apresentadas no capítulo de fundamentação teórica, a classe guarda implementa uma nova operação, chamada de submit. Essa operação encapsula o protocolo de submissão de seções críticas à guarda e pode ser utilizada por threads para a delegação da execução de seções críticas. A Listagem 8 apresenta o construtor e destrutor da guarda, assim como a implementação do método submit().
^::__Listagem 16:__ Nova convenção para a submissão de requisições de execução de seções críticas::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
// Object Methods
Guard::Guard(): _head(0), _tail(0)
{
   db<Synchronizer>(TRC)   << "Guard(head=" << _head
                           << ", tail=" << _tail
                           << ") => " << this << endl;
}

Guard::~Guard()
{
   db<Synchronizer>(TRC) << "~Guard(this=" << this << ")" << endl;
}

void Guard::submit(Closure * cs)
{
   Element * cur = vouch(&(cs->_link));
   if (cur != NULL) do {
       cur->object()->run();
       cur = clear();
   } while (cur != NULL);
}
~/np~{DIV}
{DIV}^
A implementação dos métodos vouch(...) e clear são apresentadas na Listagem 8. Essas implementações não diferem muito dos códigos apresentados no capítulo de fundamentação teórica, lembrando que a operação vouch é responsável por adicionar novos elementos à guarda e sinalizar threads quando essas precisarem assumir o papel de sequencer, e a operação clear é responsável pela remoção de elementos da guarda e por sinalizar ao sequencer quando a guarda estiver vazia.

Uma adição importante foi a deleção de seções críticas que já foram executadas. Essa deleção deve geralmente ocorrer durante a execução do método clear. No entanto, existe uma situação excepcional, que pode ocorrer quando a guarda possui apenas um elementos e operações vouch e clear executam simultaneamente. Nesse caso, a passagem do papel de sequencer da thread executando clear para a thread executando vouch. Quando isso acontecer, o sequencer executando vouch precisará também deletar o elemento da guarda previamente removido da lista pela operação clear.
^::__Listagem 17:__ Implementações de vouch() e clear()::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
Guard::Element * Guard::vouch(Element * item)
{
   db<Synchronizer>(TRC) << "Guard::vouch(this=" << this << " head= " << _head
            << " tail= " << _tail <<  ")" << endl;

   item->next(NULL);
   Element * last = CPU::fas(_tail, item);
   if (last){
       if (CPU::cas(last->_next, reinterpret_cast<Element *>(NULL), item) == NULL)
           return NULL;
       delete item->object();
   }
   _head = item;
   return item;
}

Guard::Element * Guard::clear()
{
   db<Synchronizer>(TRC) << "Guard::clear(this=" << this << " head= " << _head
            << " tail= " << _tail <<  ")" << endl;

   Element * item = _head;
   Element * next = CPU::fas(item->_next, reinterpret_cast<Element *>(DONE));
   bool mine = true;
   if (!next)
       mine = CPU::cas(_tail, item, reinterpret_cast<Element *> (NULL)) == item;
   CPU::cas(_head, item, next);
   if (mine)
       delete item->object();
   return next;
}
~/np~{DIV}
{DIV}^

!!!FAS [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]
A operação FAS, uma das duas primitivas atômicas utilizados no algoritmo das guardas, ainda não havia sido implementada no EPOS, Dessa forma, foi adicionada ao arquivo ''/include/archtecture/ia_32/cpu.h'', onde estão implementadas as primitivas atômicas de sincronização no EPOS, uma nova implementação para FAS.

O código de FAS foi inspirado no código das outras operações atômicas e nas descrições das instruções atômicas nos manuais da Intel.

Além disso, assim como ocorre com as outras operações atômicas, foi adicionada uma implementação em software, independente de arquitetura, no arquivo ''/include/cpu.h''. No entanto, como essa operação não possui suporte de hardware, ela não deve provê garantias de atomicidade.
^::__Listagem 18:__ Implementação do FAS::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
// /include/archtecture/ia_32/cpu.h
template<typename T>
static T fas(volatile T & value, volatile T replacement)
{
    ASM("lock xchg %0, %2" : "=a"(replacement) : "a"(replacement), "m"(value) : "memory");
    return replacement;
}

// /include/cpu.h
static int fas(volatile int & value, volatile int & replacement) {
     int old = value;
     value = replacement;
     return old;
 }
~/np~{DIV}
{DIV}^

!!!debug_sync.h [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]
Para auxiliar e melhorar o entendimento das aplicações multithread, foi criado uma macro especial para realizar o debug das aplicações e novos componentes do EPOS criados, como ''closure.h'', ''guard.h'' e ''stringstream.h''.

Sua implementação baseia-se somente em semáforo global uma simples macro que replica seu uso. Ela pode ser desativada completamente, não adicionando a diretiva ''#define DEBUG_SYNC'' do pré-processador C que realiza sua ativação.
^::__Listagem 19:__ Arquivo ''/include/utility/debug_sync.h''::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
// EPOS Debug Utility Declarations

#include <utility/debug.h>
#include <semaphore.h>

#ifndef __debug_sync_h
#define __debug_sync_h

// You can define it anywhere before including this file
// #define DEBUG_SYNC

#ifdef DEBUG_SYNC

__BEGIN_UTIL
    Semaphore _debug_syncronized_semaphore_lock;
__END_UTIL

    // A debug function cannot call this recursively, otherwise a deadlock happens
    #define DB(name,level,...) do { \
        _debug_syncronized_semaphore_lock.lock(); \
            db<name>(level) << __VA_ARGS__; \
        _debug_syncronized_semaphore_lock.unlock(); } while(0);

#else
    #define DB(name,level,...) db<name>(level) << __VA_ARGS__;

#endif

#define LOG(...) DB(Debug, WRN, __VA_ARGS__)

#endif
~/np~{DIV}
{DIV}^

!!!stringstream.h [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]
Para auxiliar o uso do algoritmo do ''Guarda'', e permite que faça-se a formatação prévia de strings antes de envia-las para a seção crítica, criou-se uma nova class auxiliar chamada ''StringStream'' criada no arquivo ''stringstream.h''. Ela é uma extensão simples da classe ''OStream'' do EPOS, que já sabe como fazer a formatação de vários tipos. Assim, na implementação do ''stringstream.h'' somente implementou-se um wrapper sobre a manipulação de todas as strings que já foram formatadas pela super classe ''OStream''.
^::__Listagem 20:__ Modificações do arquivo ''/include/utility/ostream.h''::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
class StringStream;

...
    // Implemented on `ostream.cc`, because `stringstream.h` includes `ostream.h`,
    // hence, `ostream.h` cannot include `stringstream.h` back (cyclic reference)
    OStream & operator<<(const StringStream * stream);

    // // ostream.cc
    // #include <utility/stringstream.h>
    //
    // OStream & OStream::operator<<(const StringStream * stream)
    // {
    //     return operator<<(stream->buffer());
    // }

private:
    virtual void print(const char * s) { _print(s); }
~/np~{DIV}
{DIV}^
Foi necessário tornar o método ''print()'' da classe ''OStream'' virtual e para facilitar o uso, também permitiu-se que classe ''OStream'' possa imprimir diretamente ponteiros do tipo ''StringStream''. Entretanto, depois de declarar o método ''print()'' com o modificador ''virtual'', faz-se com que não se tenha nenhuma saída de texto ao executar a aplicação.

No exemplo a seguir, vê-se a execução de uma aplicação no modo ''hysterically_debugged = true'' após adicionar-se o modificador ''virtual'' na assinatura da função ''void print(const char * s) { _print(s); }''.
^::__Listagem 21:__ Saída da execução de uma aplicação com ''hysterically_debugged = true''::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
EPOS bootable image tool

  EPOS mode: library
  Machine: pc
  Model: legacy_pc
  Processor: ia32 (32 bits, little-endian)
  Memory: 262144 KBytes
  Boot Length: 512 - 512 (min - max) KBytes
  Node id: will get from the network
  EPOS Image UUID: 7bb9c483078f0692
  Creating EPOS bootable image in "scheduler_cpu_affinity_test.img":
    Adding boot strap "/home/linux/OperatingSystems/Epos2x86/img/pc_boot": done.
    Adding setup "/home/linux/OperatingSystems/Epos2x86/img/pc_setup": done.
    Adding application "scheduler_cpu_affinity_test": done.
    Adding system info: done.

  Adding specific boot features of "pc": done.

  Image successfully generated (172868 bytes)!

make[2]: Leaving directory '/home/linux/OperatingSystems/Epos2x86/img'
(cd img && make --print-directory run)
make[2]: Entering directory '/home/linux/OperatingSystems/Epos2x86/img'
# qemu-system-i386 -smp 2 -m 262144k -nographic -no-reboot -drive format=raw,index=0,if=floppy,file=scheduler_cpu_affinity_test.img | tee scheduler_cpu_affinity_test.out
qemu-system-i386 -smp 2 -m 262144k -nographic -no-reboot -drive format=raw,index=0,if=floppy,file=scheduler_cpu_affinity_test.img
<0>: make[2]: Leaving directory '/home/linux/OperatingSystems/Epos2x86/img'
make[1]: Leaving directory '/home/linux/OperatingSystems/Epos2x86'
~/np~{DIV}
{DIV}^
Percebe-se que ao compilar e executar a aplicação ''guard_scheduler_cpu_affinity_test.cc'', em modo debug histérico, a única coisa que foi impresso no tela foi a primeira parte ''<0>: '' da mensagem que indica qual CPU está executando aquela mensagem. Mas basta remover-ser o identificador ''virtual'' da função ''OStream::print'', que tudo volta a funcionar normalmente.

Portando, devido ao bug com o uso da identificador ''virtual'', fez-se o uso de outra alternativa mais agressiva do que o polimorfismo permitido pelo identificador ''virtual''. Após muita pesquisa, chegou-se a uma implementação que faz uso de muitos ''static_cast'''s e utiliza-se métodos estáticos para permitir que o objeto que derivam da super classe possam funcionar correta, 'imitando' o funcionamento que se obtém-se com o uso do identificador ''virtual''.

Agora, tem-se uma nova super classe meta programada chamada ''OStream_Base'', que será base de todas os tipos de stream, incluindo ''OStream'' e o novo tipo ''StringStream''. A seguir encontra-se a sua implementação:
^::__Listagem 22:__ Arquivo ''/include/utility/ostream.h''::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
template<class StreamType>
class OStream_Base
{
public:
    struct Begl {};
    struct Endl {};

    struct Hex {};
    struct Dec {};
    struct Oct {};
    struct Bin {};

public:
    OStream_Base(): _base(10) {}

    StreamType& operator<<(const Hex & hex) {
        _set_base(16);
        return *static_cast<StreamType*>(this);
    }
    StreamType& operator<<(const Dec & dec) {
        _set_base(10);
        return *static_cast<StreamType*>(this);
    }
    StreamType& operator<<(const Oct & oct) {
        _set_base(8);
        return *static_cast<StreamType*>(this);
    }
    StreamType& operator<<(const Bin & bin) {
        _set_base(2);
        return *static_cast<StreamType*>(this);
    }

    StreamType& operator<<(char c) {
        char buf[2];
        buf[0] = c;
        buf[1] = '\0';
        print(buf);
        return *static_cast<StreamType*>(this);
    }
    StreamType& operator<<(unsigned char c) {
        return operator<<(static_cast<unsigned int>(c));
    }

    StreamType& operator<<(int i) {
        char buf[64];
        buf[itoa(i, buf)] = '\0';
        print(buf);
        return *static_cast<StreamType*>(this);
    }
    StreamType& operator<<(short s) {
        return operator<<(static_cast<int>(s));
    }
    StreamType& operator<<(long l) {
        return operator<<(static_cast<int>(l));
    }

    StreamType& operator<<(unsigned int u) {
        char buf[64];
        buf[utoa(u, buf)] = '\0';
        print(buf);
        return *static_cast<StreamType*>(this);
    }
    StreamType& operator<<(unsigned short s) {
        return operator<<(static_cast<unsigned int>(s));
    }
    StreamType& operator<<(unsigned long l) {
        return operator<<(static_cast<unsigned int>(l));
    }

    StreamType& operator<<(long long int u) {
        char buf[64];
        buf[llitoa(u, buf)] = '\0';
        print(buf);
        return *static_cast<StreamType*>(this);
    }

    StreamType& operator<<(unsigned long long int u) {
        char buf[64];
        buf[llutoa(u, buf)] = '\0';
        print(buf);
        return *static_cast<StreamType*>(this);
    }

    StreamType& operator<<(const void * p) {
        char buf[64];
        buf[ptoa(p, buf)] = '\0';
        print(buf);
        return *static_cast<StreamType*>(this);
    }

    StreamType& operator<<(const char * s) {
        print(s);
        return *static_cast<StreamType*>(this);
    }

    StreamType& operator<<(float f) {
        if(f < 0.0001f && f > -0.0001f)
            (*this) << "0.0000";

        int b = 0;
        int m = 0;

        float x = f;
        if(x >= 0.0001f) {
            while(x >= 1.0000f) {
                x -= 1.0f;
                b++;
            }
            (*this) << b << ".";
            for(int i = 0; i < 3; i++) {
                m = 0;
                x *= 10.0f;
                while(x >= 1.000f) {
                    x -= 1.0f;
                    m++;
                }
                (*this) << m;
            }
        } else {
            while(x <= -1.000f) {
                x += 1.0f;
                b++;
            }
            (*this) << "-" << b << ".";
            for(int i = 0; i < 3; i++) {
                m = 0;
                x *= 10.0f;
                while(x <= -1.000f) {
                    x += 1.0f;
                    m++;
                }
                (*this) << m;
            }
        }
        return *static_cast<StreamType*>(this);
    }

protected:
    int itoa(int v, char * s)
    {
        unsigned int i = 0;

        if(v < 0) {
            v = -v;
            s[i++] = '-';
        }

        return utoa(static_cast<unsigned int>(v), s, i);
    }

    int utoa(unsigned int v, char * s, unsigned int i = 0)
    {
        unsigned int j;

        if(!v) {
            s[i++] = '0';
            return i;
        }

        if(v > 256) {
            if(_base == 8 || _base == 16)
                s[i++] = '0';
            if(_base == 16)
                s[i++] = 'x';
        }

        for(j = v; j != 0; i++, j /= _base);
        for(j = 0; v != 0; j++, v /= _base)
            s[i - 1 - j] = _digits[v % _base];

        return i;
    }

    int llitoa(long long int v, char * s)
    {
        unsigned int i = 0;

        if(v < 0) {
            v = -v;
            s[i++] = '-';
        }

        return llutoa(static_cast<unsigned long long int>(v), s, i);
    }

    int llutoa(unsigned long long int v, char * s, unsigned int i = 0)
    {
        unsigned long long int j;

        if(!v) {
            s[i++] = '0';
            return i;
        }

        if(v > 256) {
            if(_base == 8 || _base == 16)
                s[i++] = '0';
            if(_base == 16)
                s[i++] = 'x';
        }

        for(j = v; j != 0; i++, j /= _base);
        for(j = 0; v != 0; j++, v /= _base)
            s[i - 1 - j] = _digits[v % _base];

        return i;
    }

    int ptoa(const void * p, char * s)
    {
        unsigned int j, v = reinterpret_cast<unsigned int>(p);

        s[0] = '0';
        s[1] = 'x';

        for(j = 0; j < sizeof(void *) * 2; j++, v >>= 4)
            s[2 + sizeof(void *) * 2 - 1 - j]
                = _digits[v & 0xf];

        return j + 2;
    }

    // https://stackoverflow.com/questions/34222703/how-to-override-static-method
    inline void print(const char * s)
        { StreamType::print(static_cast<StreamType*>(this), s); }

    inline void _set_base(int v) { _base = v; }

    int _base;
    static const char _digits[];
};

// Class Attributes
// https://stackoverflow.com/questions/3531060/how-to-initialize-a-static-const-member
template<class OStream>
const char OStream_Base<OStream>::_digits[] = "0123456789abcdef";
~/np~{DIV}
{DIV}^
Como por padrão o operator de stream ''operator<<'' returna um objeto o mesmo tipo que a classe atual, e não da classe derivada, tem-se o problema de perder-se o tipo do objeto quando utiliza-se os métodos herdados da super classe. Por isso a classe base, agora é uma meta classe, e realiza a conversão do retorno de todos os seus operadores de stream ''operator<<''.

Para contornar o problema de não poder-se utilizar o identificador ''virtual'' no método ''inline void print(const char * s)'' logo acima, faz-se uso da meta programação com template ''StreamType'', para acessar diretamente o método estático da classe derivada passando como primeiro parâmetro o ponteiro para o objeto do tipo da classe derivada, após realizar sua conversão ''StreamType::print(static_cast<StreamType*>(this), s)''.

Assim, após refatorar-se todo o conteúdo da antiga ''OStream'', tem-se uma nova ''OStream'' que deriva da super classe ''OStream_Base'':
^::__Listagem 23:__ Arquivo ''/include/utility/ostream.h''::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
// https://stackoverflow.com/questions/11761506/inheritance-function-that-returns-self-type
class OStream : public OStream_Base<OStream>
{
public:
    struct Err {};

public:
    OStream(): _error(false) {}

    // Implemented on `ostream.cc`, because `stringstream.h` includes `ostream.h`,
    // hence, `ostream.h` cannot include `stringstream.h` back (cyclic reference)
    OStream & operator<<(const StringStream * stream);

    OStream & operator<<(const Begl & begl) {
        if(Traits<System>::multicore)
            _print_preamble();
        return *this;
    }

    OStream & operator<<(const Endl & endl) {
        if(Traits<System>::multicore)
            _print_trailler(_error);
        OStream_Base<OStream>::print("\n");
        _set_base(10);
        return *this;
    }

    OStream & operator<<(const Err & err) {
        _error = true;
        return *this;
    }

    using OStream_Base<OStream>::operator<<;

    // Adding virtual to the print() function caused EPOS to completely break
    static void print(OStream* that, const char * s) { _print(s); }

private:
    volatile bool _error;
};
~/np~{DIV}
{DIV}^
Agora, a implementação do novo tipo ''StringStream'' resume-se ao seguinte:
^::__Listagem 24:__ Arquivo ''/include/utility/stringstream.h''::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
class StringStream : public OStream_Base<StringStream>
{
private:
    char* _buffer;
    unsigned int _last_position;
    const unsigned int _buffer_size;

public:
    StringStream(const unsigned int _buffer_size) :
            _last_position(0), _buffer_size(_buffer_size)
    {
        DB( Synchronizer, TRC, "StringStream::StringStream(_buffer_size="
                << _buffer_size << ") => " << reinterpret_cast<int *>(this) << endl )

        assert(_buffer_size > 0);
        _buffer = new char[_buffer_size];
    }

    ~StringStream() {
        DB( Synchronizer, TRC, "StringStream::~StringStream(this="
                << reinterpret_cast<int *>(this) << ", _buffer="
                << reinterpret_cast<int *>(_buffer) << ")" << endl )

        delete _buffer;
    }

    const char * const buffer() const {
        return _buffer;
    }

    StringStream & operator<<(const StringStream & stream) {
        OStream_Base<StringStream>::print(stream.buffer());
        return *this;
    }
    StringStream & operator<<(const StringStream * stream) {
        OStream_Base<StringStream>::print(stream->buffer());
        return *this;
    }

    static void print(StringStream* that, const char* string) {
        DB( Synchronizer, TRC, "StringStream::print(this="
                << reinterpret_cast<int *>(that)
                << "), string=" << string << ", " )

        unsigned int string_size = strlen(string);
        unsigned int total_size = string_size + that->_last_position;

        DB( Synchronizer, TRC, "string_size=" << string_size << ", "
                << "total_size=" << total_size )

        // https://linux.die.net/man/3/strncpy
        if( total_size >= that->_buffer_size ) {
            total_size = that->_buffer_size - 1;

            strncpy(&that->_buffer[that->_last_position],
                    string, total_size - that->_last_position);

            that->_buffer[total_size] = '\0';
        }
        else {
            strcpy(&that->_buffer[that->_last_position], string);
        }

        that->_last_position = total_size;
        DB( Synchronizer, TRC, ", _last_position=" << that->_last_position
                << ", _buffer=" << that->_buffer << endl )
    }

public:
    StringStream & operator<<(const Begl & begl) {
        return *this;
    }

    StringStream & operator<<(const Endl & endl) {
        OStream_Base<StringStream>::print("\n");
        _set_base(10);
        return *this;
    }

    using OStream_Base<StringStream>::operator<<;
};
~/np~{DIV}
{DIV}^
Segue-se alguns testes de extremo de uso da ''StringStream'', quando o buffer está quase cheio:
^::__Listagem 25:__ Arquivo ''/app/stringstream_test.cc''::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
// EPOS Semaphore Component Test Program
#define DEBUG_SYNC

#include <utility/stringstream.h>
using namespace EPOS;

int main()
{
    LOG( endl )
    LOG( "Welcome to the `stringstream.h` test program" << endl )

    StringStream stream48chars{50};
    StringStream stream49chars{50};
    StringStream stream50chars{50};
    StringStream stream51chars{50};

    stream48chars << "666666666666666666666666666666666666666666660048";
    stream49chars << "6666666666666666666666666666666666666666666600049";
    stream50chars << "66666666666666666666666666666666666666666666000050";
    stream51chars << "666666666666666666666666666666666666666666660000051";

    LOG( &stream48chars << endl )
    LOG( &stream49chars << endl )
    LOG( &stream50chars << endl )
    LOG( &stream51chars << endl << endl )

    StringStream base23chars{50};
    StringStream stream48chars2{50};
    StringStream stream49chars2{50};
    StringStream stream50chars2{50};
    StringStream stream51chars2{50};

    base23chars    << "77777777777777777777777";
    stream48chars2 << base23chars << "8888888888888888888880048";
    stream49chars2 << base23chars << "88888888888888888888800049";
    stream50chars2 << base23chars << "888888888888888888888000050";
    stream51chars2 << base23chars << "8888888888888888888880000051";

    LOG( &stream48chars2 << endl )
    LOG( &stream49chars2 << endl )
    LOG( &stream50chars2 << endl )
    LOG( &stream51chars2 << endl )

    return 0;
}
~/np~{DIV}
{DIV}^
Resultado da execução:
^::__Listagem 26:__ Arquivo ''/app/stringstream_test.cc''::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
Welcome to the `stringstream.h` test program
666666666666666666666666666666666666666666660048
6666666666666666666666666666666666666666666600049
6666666666666666666666666666666666666666666600005
6666666666666666666666666666666666666666666600000

777777777777777777777778888888888888888888880048
7777777777777777777777788888888888888888888800049
7777777777777777777777788888888888888888888800005
7777777777777777777777788888888888888888888800000
~/np~{DIV}
{DIV}^

!!!Parallel Makefile [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]
Para auxiliar o desenvolvimento, reduzindo o tempo de espera pela compilação completa do EPOS com um ''make veryclean'', foi paralelizado a compilação do EPOS alterando alguns ''Makefile'''s:
# ''src/architecture/makefile''
# ''src/component/makefile''
# ''src/machine/makefile''
# ''src/utility/makefile''
# ''tools/makefile''
A alteração feita nesses ''Makefile'''s foi a seguinte:
^::__Listagem 27:__ Novo ''makefile'' paralelizado::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
# How can I write a makefile to auto-detect and parallelize the build with GNU Make?
# https://stackoverflow.com/questions/2527496/how-can-i-write-a-makefile-to-auto
ifeq ($J,)
    ifeq ($(OS),Windows_NT)
        NPROCS := $(NUMBER_OF_PROCESSORS)
    else
        ifeq ($(UNAME),Darwin)
          NPROCS := $(shell sysctl -n hw.ncpu)
        else
          NPROCS := $(shell grep -c ^processor /proc/cpuinfo)
        endif
    endif
else
  NPROCS := ""
endif
all:
    ${MAKE} all_multithread -j$(NPROCS)
all_multithread: $(SUBDIRS)
~/np~{DIV}
{DIV}^
A alteração não foi feita somente no ''Makefile'' raíz por que alguns ''Makefile'''s como ''src/system'' precisam ser executados sequencialmente. A seleção de quais ''Makefile'''s poderiam ser paralelizados foi feita pela tentativa e erro. Adicionava-se o comando de paralelização, e verifica-se o EPOS compilava corretamente depois de um ''make veryclean''.

Para paralelizar o comando ''make veryclean'', simplesmente precisou-se editar o ''Makefile'' raíz ''src/makefile'', adicionado o seguinte comando:
^::__Listagem 28:__ Novo comando ''make clean''::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
clean:
    ${MAKE} clean_multithread -j$(NPROCS)
clean_multithread:
~/np~{DIV}
{DIV}^
Para ''make veryclean'' funcionar paralelamente, foi preciso remover a definição ''MAKECLEAN'' no arquivo principal ''makedefs'' [https://github.com/evandrocoan/asynchronous_critical_sections/commit/a020ccdb4216bb8131e7d86e3c99c6b95d726d0a|4237faf] && [https://github.com/evandrocoan/asynchronous_critical_sections/commit/5dfd5d7a53ebbf77c33816beec785201c8d7a1c5|e4faae6], por que para que o comando ''-j'' de paralelização do ''Makefile'' funcione, as chamadas recursivas de makefile precisam ser feitas utilizando a variável ''${MAKE}'' ao contrário de chamar o make file diretamente como ''MAKECLEAN := make -i clean'' fazia.

!!!Assert
Durante o desenvolvimento do trabalho, foi habilitado as instruções de assert do EPOS, no arquivo ''/include/system/config.h''. Entretanto, ao fazer isso, foram relevados alguns erros de compilação e de execução do EPOS.

Um dos erros relevados pelos asserts foi construtor da classe ''Thread'', que deixa de ser atômico quando compila-se o EPOS para várias CPU's. Ao executar o trecho de código do construtor da classe ''Thread'' a seguir, as interrupções são ligadas pelo operator new. Isso, é um problema por que o construtor da classe ''Thread'' inicia com um ''lock()'' e termina com um ''unlock()'', portanto, não pode-se ter alguém no meio do processo reativando as interrupções.
^::__Listagem 29:__ Trecho do construtor de ''/src/component/thread.cc''::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
// Somewhere on the new operator, it is being called enable() and disable() CPU interrupt
if(Traits<MMU>::colorful && color != WHITE)
    _stack = new (color) char[stack_size];
else
    _stack = new (SYSTEM) char[stack_size];
~/np~{DIV}
{DIV}^
Para resolver-se esse problema, tentou-se estudar o código do operador de new, para encontrar onde tal anomalia estava acontecendo. Entretanto, mesmo que descoberto onde isso esteja acontecendo, tentar alterar ou modificar tal código, seria muito problemático. Portanto, ao contrario de lutar contra o problema, abraçou-se ele. Assim, modificou-se arquivo ''cpu.h'' adicionado-se o suporte a uma pilha de chamadas ''lock()'' e ''unlock()''. Assim, pode-se recursivamente chamar funções que precisa ser atómicas, garantido que a chamada mais externa continuará sempre atômica.
^::__Listagem 30:__ Mudanças no arquivo ''/include/architecture/ia32/cpu.h''::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
static void int_enable()
{
    if( int_disabled() )
    {
        if( _not_reenable == 0 ) {
            ASM("sti");
        }
        else {
            _not_reenable -= 1;
        }
    }
}

static void int_disable()
{
    if( int_enabled() ) {
        ASM("cli");
    }
    else {
        _not_reenable += 1;
    }
}
~/np~{DIV}
{DIV}^
A seguir, vê-se um resumo das commits com errors relacionadas a ativação do assert.
^::__Listagem 31:__ Lista de commits criadas pela ativação do ''assert()''::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
Date:   Tue Nov 13 16:55:14 2018 -0200
    Enabled asserts on config.h

diff --git a/include/system/config.h b/include/system/config.h
index 23e2476..83b045b 100644
--- a/include/system/config.h
+++ b/include/system/config.h
@@ -71,8 +71,8 @@ namespace EPOS {
 //============================================================================
 // ASSERT (for pre and post conditions)
 //============================================================================
-//#define assert(expr)    ((expr) ? static_cast<void>(0) : Assert::fail (#expr, __FILE__, __LINE__, __PRETTY_FUNCTION__))
-#define assert(expr)    (static_cast<void>(0))
+#define assert(expr)    ((expr) ? static_cast<void>(0) : Assert::fail (#expr, __FILE__, __LINE__, __PRETTY_FUNCTION__))
+// #define assert(expr)    (static_cast<void>(0))

 //============================================================================
 // CONFIGURATION


Date:   Tue Nov 13 16:55:03 2018 -0200
    Make the debug.h assert messages more visible

diff --git a/include/utility/debug.h b/include/utility/debug.h
index 6508d48..ade97f7 100644
--- a/include/utility/debug.h
+++ b/include/utility/debug.h
@@ -116,7 +116,7 @@ class Assert
 {
 public:
     static void fail(const char * __assertion, const char * __file, unsigned int __line, const char * __function) {
-        db<void>(ERR) << "Assertion fail: " << __assertion << ", function=" << __function << ", file=" << __file << ", line=" << __line << endl;
+        db<void>(ERR) << endl << endl << "Assertion fail: " << __assertion << ", function=" << __function << ", file=" << __file << ", line=" << __line << endl << endl;
     }
 };


Date:   Tue Nov 13 16:51:29 2018 -0200
    Fixed tstp.h:1255: error: incomplete type 'EPOS::S::Cipher' used in
    nested name specifier.

diff --git a/include/tstp.h b/include/tstp.h
index cd593d1..8cbfbc3 100644
--- a/include/tstp.h
+++ b/include/tstp.h
@@ -1251,7 +1251,8 @@ public:

             db<TSTP>(INF) << "Node ID: " << _id << endl;

-            assert(Cipher::KEY_SIZE == sizeof(Node_ID));
+            // There is not cipher.h header
+            // assert(Cipher::KEY_SIZE == sizeof(Node_ID));
             _cipher.encrypt(_id, _id, _auth);
         }
         ~Security();


Date:   Tue Nov 13 16:20:05 2018 -0200
    Fixed ic.h:503: error: array subscript is above array bounds

diff --git a/include/machine/pc/ic.h b/include/machine/pc/ic.h
index 49c8f00..4aabea4 100644
--- a/include/machine/pc/ic.h
+++ b/include/machine/pc/ic.h
@@ -499,8 +499,11 @@ public:
     static void int_vector(const Interrupt_Id & i, const Interrupt_Handler & h) {
         db<IC>(TRC) << "IC::int_vector(int=" << i << ",h=" << reinterpret_cast<void *>(h) <<")" << endl;
         assert(i < INTS);
+        // When enabling the asserts expressions, the compiler keeps complaining about
         // WARNING: in static member function 'static void EPOS::S::FPGA::init()': error: array subscript is above array bounds
-        _int_vector[i] = h;
+        // Then, do some hack to overrule it  and let the above assert() do its thing on runtime.
+        unsigned int index = i >= INTS ? INTS - 1 : i;
+        _int_vector[index] = h;
     }

     static void enable() {


Date:   Tue Nov 13 16:14:31 2018 -0200
    Fixed pmu.h:602: assert error: comparison between signed and unsigned
    integer expressions

diff --git a/include/architecture/ia32/pmu.h b/include/architecture/ia32/pmu.h
index e8f7cc7..7184c17 100644
--- a/include/architecture/ia32/pmu.h
+++ b/include/architecture/ia32/pmu.h
@@ -599,7 +599,7 @@ public:
     Intel_Sandy_Bridge_PMU() {}

     static bool config(const Channel & channel, const Event & event, const Flags & flags = NONE) {
-        assert((channel < CHANNELS) && (event < EVENTS));
+        assert((channel < CHANNELS) && (static_cast<unsigned int>(event) < EVENTS));
         db<PMU>(TRC) << "PMU::config(c=" << channel << ",e=" << event << ",f=" << flags << ")" << endl;

         if(((channel == 0) && (event != INSTRUCTION)) || ((channel == 1) && (event != DVS_CLOCK)) || ((channel == 2) && (event != CLOCK))) {


Date:   Tue Nov 13 16:11:18 2018 -0200
    Fixed assert error: 'i' was not declared in this scope on ic.h

diff --git a/include/machine/pc/ic.h b/include/machine/pc/ic.h
index a85fbcb..49c8f00 100644
--- a/include/machine/pc/ic.h
+++ b/include/machine/pc/ic.h
@@ -505,7 +505,7 @@ public:

     static void enable() {
         db<IC>(TRC) << "IC::enable()" << endl;
-        assert(i < INTS);
+        // assert(i < INTS);
         Engine::enable();
     }

@@ -517,7 +517,7 @@ public:

     static void disable() {
         db<IC>(TRC) << "IC::disable()" << endl;
-        assert(i < INTS);
+        // assert(i < INTS);
         Engine::disable();
     }


Date:   Thu Nov 15 16:01:15 2018 -0200
    Fixed the thread.cc constructor not being atomic while building
    EPOS with multiple CPUs.
diff --git a/include/architecture/ia32/cpu.h b/include/architecture/ia32/cpu.h
index d6d51d2..1ced73e 100644
--- a/include/architecture/ia32/cpu.h
+++ b/include/architecture/ia32/cpu.h
@@ -313,8 +313,29 @@ public:
     static Hertz clock() { return _cpu_clock; }
     static Hertz bus_clock() { return _bus_clock; }

-    static void int_enable() { ASM("sti"); }
-    static void int_disable() { ASM("cli"); }
+    static void int_enable()
+    {
+        if( int_disabled() )
+        {
+            if( _not_reenable == 0 ) {
+                ASM("sti");
+            }
+            else {
+                _not_reenable -= 1;
+            }
+        }
+    }
+
+    static void int_disable()
+    {
+        if( int_enabled() ) {
+            ASM("cli");
+        }
+        else {
+            _not_reenable += 1;
+        }
+    }
+
     static bool int_enabled() { return (flags() & FLAG_IF); }
     static bool int_disabled() { return !int_enabled(); }

@@ -624,6 +645,7 @@ private:
     static void init();

 private:
+    static int _not_reenable;
     static unsigned int _cpu_clock;
     static unsigned int _bus_clock;
 };
diff --git a/src/architecture/ia32/cpu.cc b/src/architecture/ia32/cpu.cc
index 8357fa0..e712aa2 100644
--- a/src/architecture/ia32/cpu.cc
+++ b/src/architecture/ia32/cpu.cc
@@ -8,6 +8,7 @@ extern "C" { void _exec(void *); }
 __BEGIN_SYS

 // Class attributes
+int CPU::_not_reenable = 0;
 unsigned int CPU::_cpu_clock;
 unsigned int CPU::_bus_clock;

diff --git a/src/component/thread.cc b/src/component/thread.cc
index 9495641..27dd942 100644
--- a/src/component/thread.cc
+++ b/src/component/thread.cc
@@ -26,6 +26,7 @@ void Thread::constructor_prologue(const Color & color, unsigned int stack_size)
     _thread_count++;
     _scheduler.insert(this);

+    // Somewhere on the new operator, it is being called enable() and disable() CPU interrupt
     if(Traits<MMU>::colorful && color != WHITE)
         _stack = new (color) char[stack_size];
     else
@@ -50,10 +51,14 @@ void Thread::constructor_epilogue(const Log_Addr & entry, unsigned int stack_siz
     if((_state != READY) && (_state != RUNNING))
         _scheduler.suspend(this);

-    if(preemptive && (_state == READY) && (_link.rank() != IDLE))
+    if(preemptive && (_state == READY) && (_link.rank() != IDLE)) {
+        db<Scheduler<Thread> >(TRC) << "Thread::constructor_epilogue(locked=" << locked() << ")" << endl;
+        assert(locked());
         reschedule(_link.rank().queue());
-    else
+    }
+    else {
         unlock();
+    }
 }


@@ -124,6 +129,9 @@ void Thread::priority(const Priority & c)
     }

     if(preemptive) {
+        db<Scheduler<Thread> >(TRC) << "Thread::priority(locked=" << locked() << ")" << endl;
+        assert(locked());
+
         reschedule(old_cpu);
         if(smp) {
             lock();
@@ -312,6 +320,7 @@ void Thread::wakeup_all(Queue * q)
 void Thread::reschedule()
 {
     db<Scheduler<Thread> >(TRC) << "Thread::reschedule()" << endl;
+    db<Scheduler<Thread> >(TRC) << "Thread::reschedule(locked=" << locked() << ")" << endl;

     // lock() must be called before entering this method
     assert(locked());
@@ -325,6 +334,10 @@ void Thread::reschedule()

 void Thread::reschedule(unsigned int cpu)
 {
+    db<Scheduler<Thread> >(TRC) << "Thread::reschedule(cpu=" << cpu << ")" << endl;
+    db<Scheduler<Thread> >(TRC) << "Thread::reschedule(locked=" << locked() << ")" << endl;
+    assert(locked());
+
     if(!smp || (cpu == Machine::cpu_id()))
         reschedule();
     else {
@@ -338,6 +351,8 @@ void Thread::reschedule(unsigned int cpu)
 void Thread::rescheduler(const IC::Interrupt_Id & interrupt)
 {
     lock();
+    // if( Traits<IC>::dispatch_debugged )
+    db<Synchronizer>(TRC) << "Thread::rescheduler(interrupt=" << interrupt << ")" << endl;

     reschedule();
 }
~/np~{DIV}
{DIV}^
!!!Futures [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]
Das 2 implementações distintas de futures apresentadas, realiza-se a implementação do modelo de future bloqueante, apresentado no artigo referência {DIV(type="span")}[{DIV}[#Refer_ncias_|2]]. Como a implementação atual do algoritmo do guarda não suporta passagens de parâmetros variádicos, fez-se a implementação dos métodos para que aceitem vários parâmetros com meta programação. Ver a seção [#Closure_Metaprogramada_|Closure Metaprogramada].

Uma vez que a future é resolvida, i.e., seu método ''resolve()'' é chamado e seu valor é definido, ele não pode ser mais alterado, e qualquer um que tentar obter o valor da future com ''get_value()'' não precisará mais bloquear, pois o valor não é indefinido. Futures são implementadas totalmente no arquivo header ''.h'' por que são meta classes que são instanciadas pelo compilador e seu código é gerado somente caso alguém crie uma especialização com algum tipo de dado.
^::__Listagem 32:__ Implementação de future em ''/include/utility/future.h''::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
// EPOS Guard Component Declarations

#ifndef __future_h
#define __future_h

#include <condition.h>

__BEGIN_UTIL

template<typename FutureType>
class Future
{
public:
    Future(): _condition(), _is_resolved() {
        db<Synchronizer>(WRN)   << "Future(_is_resolved=" << _is_resolved
                                << ", _condition=" << _condition.size()
                                << ") => " << this << endl;
    }

    ~Future() {
        db<Synchronizer>(WRN) << "~Future(this=" << this << ")" << endl;
    }

    FutureType get_value() {
        db<Synchronizer>(WRN) << "Future::get_value(this=" << this
                              << " _is_resolved=" << _is_resolved
                              << " _condition=" << _condition.size()
                              <<  ")" << endl;
        if(!_is_resolved) _condition.wait();
        return _value;
    }

    void resolve(FutureType value) {
        db<Synchronizer>(WRN) << "Future::resolve(this=" << this
                              << " _is_resolved=" << _is_resolved
                              << " _condition=" << _condition.size()
                              <<  ")" << endl;
        assert(!_is_resolved);
        // If `resolve()` was called and the instruction pointer got until here,
        // and the thread is unscheduled, and another thread call `resolve()`,
        // then, the `assert` above will not work.
        _value = value;
        _is_resolved = true;
        _condition.broadcast();
    }

private:
    bool _is_resolved;
    FutureType _value;
    Condition _condition;
};

__END_UTIL

#endif
~/np~{DIV}
{DIV}^
Agora ve-sê um simples programa que demonstra o uso de futures:
^::__Listagem 33:__ Arquivo de Teste ''/app/future_simple_test.cc''::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
// EPOS Synchronizer Component Test Program
#define DEBUG_SYNC

#include <thread.h>
#include <utility/future.h>
#include <semaphore.h>
#include <alarm.h>

using namespace EPOS;

int producerFunction(Future<int>* future) {
    LOG( "producerFunction ()" << endl )
    Delay thinking(1000000);
    future->resolve(10);

    LOG( "producerFunction (resolving future=" << future << " to 10)" << endl )
    return 0;
}

int consumerFunction(Future<int>* future) {
    LOG( "consumerFunction ()" << endl )

    auto value = future->get_value();
    LOG( "consumerFunction (result=" << value << ")" << endl )

    value = future->get_value();
    LOG( "consumerFunction (result=" << value << ")" << endl )
    return 0;
}

int main()
{
    LOG( endl )
    LOG( "Starting main application..." << endl )
    Future<int>* future = new Future<int>();

    Thread* consumer = new Thread(&consumerFunction, future);
    Thread* producer = new Thread(&producerFunction, future);

    consumer->join();
    producer->join();

    LOG( "Exiting main application..." << endl )
    return 0;
}
~/np~{DIV}
{DIV}^
Resultado da execução:
^::__Listagem 34:__ Arquivo ''/app/future_simple_test.cc''::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
Starting main application...
Future(_is_resolved=0, _condition=0) => 0x00097f5c
consumerFunction ()
Future::get_value(this=0x00097f5c _is_resolved=0 _condition=0)
producerFunction ()
Future::resolve(this=0x00097f5c _is_resolved=0 _condition=1)
consumerFunction (result=10)
Future::get_value(this=0x00097f5c _is_resolved=1 _condition=0)
consumerFunction (result=10)
producerFunction (resolving future=0x00097f5c to 10)
Exiting main application...
~/np~{DIV}
{DIV}^
A seguir vê-se um simples exemplo de uso de futures. Nesse exemplo, evolve-se varias classes to EPOS, fazendo seu uso em conjunto com o algoritmo do guarda.
^::__Listagem 35:__ Arquivo de Teste ''/app/future_guard_test.cc''::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
// EPOS Synchronizer Component Test Program
#define DEBUG_SYNC

#include <thread.h>
#include <utility/guard.h>
#include <utility/future.h>
#include <semaphore.h>
#include <alarm.h>

using namespace EPOS;
static volatile int counter = 0;

Guard guard;

void increment_counter(Future<int>* future) {
    Delay thinking(1000000);
    counter = counter + 1;

    LOG( "increment_counter (counter=" << counter << ")" << endl )
    future->resolve(counter);
}

int functionA() {
    LOG( "functionA ()" << endl )
    Future<int>* future = new Future<int>();

    guard.submit(&increment_counter, future);
    auto value = future->get_value();

    LOG( "functionA (result=" << value << ")" << endl )
    return 0;
}

int functionB() {
    LOG( "functionB ()" << endl )
    Future<int>* future = new Future<int>();

    guard.submit(&increment_counter, future);
    auto value = future->get_value();

    LOG( "functionB (result=" << value << ")" << endl )
    return 0;
}

int main()
{
    LOG( endl )
    LOG( "Starting main application..." << endl )

    Thread* producer = new Thread(&functionA);
    Thread* consumer = new Thread(&functionB);

    consumer->join();
    producer->join();

    LOG( "Exiting main application..." << endl )
    return 0;
}
~/np~{DIV}
{DIV}^
Resultado da execução:
^::__Listagem 36:__ Arquivo ''/app/future_guard_test.cc''::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
Starting main application...
functionA ()
Future(_is_resolved=0, _condition=0) => 0x0008fef4
functionB ()
Future(_is_resolved=0, _condition=0) => 0x0008feb4
Future::get_value(this=0x0008feb4 _is_resolved=0 _condition=0)
increment_counter (counter=1)
Future::resolve(this=0x0008fef4 _is_resolved=0 _condition=0)
increment_counter (counter=2)
Future::resolve(this=0x0008feb4 _is_resolved=0 _condition=1)
functionB (result=2)
Future::get_value(this=0x0008fef4 _is_resolved=1 _condition=0)
functionA (result=1)
Exiting main application...
~/np~{DIV}
{DIV}^

!!!Closure Metaprogramada [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]
A ''Critical_Section'' inicialmente descrita não apresenta a possibilidade de definir-se/criar-se funções com um número variado de argumentos. Por isso, essa implementação foi substituída por uma ''Critical_Section'' meta programada, que faz uso de templates variádicos do C++ 11.

A seguir ve-sê a implementação da classe base de todas as ''Critical_Section''. Uma classe base é necessária por que o algoritmo do Guarda implementa uma lista encadeada de seções críticas, que em nosso caso são presentados por ''Closures''. Assim, como a implementação de lista, que o algoritmo do Guarda faz uso, não permite que tipos diferentes sejam adicionados na lista, faz-se uso do polimorfismo para criar um lista com diferentes closures meta programadas.
^::__Listagem 37:__ Base de todas ''Closures'' meta programadas, Arquivo: ''/include/utility/critical_section.h''::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
class Critical_Section_Base
{
    /// The Guard class requires access to our the _link private attribute
    friend class Guard;
    typedef List_Elements::Singly_Linked<Critical_Section_Base> Element;

public:
    Critical_Section_Base(): _link(this) {
        db<Synchronizer>(TRC) << "Critical_Section_Base(_link=" << &_link
                << ") => " << this << endl;
    }

    /// This must to be virtual otherwise the derived classes objects destructor
    /// method would not be called when accessed by a base class pointer.
    virtual ~Critical_Section_Base() {
        db<Synchronizer>(TRC) << "~Critical_Section_Base(this=" << this
                << " _link=" << &_link << ")" << endl;
    }

    /// Returns void because the base class Critical_Section_Base() cannot be a
    /// template class, as it is general interface for all Closures used on the
    /// Guard algorithm. Also, it does not make sense to return something from
    /// the closure when in its code is ran by the sequencer on another thread,
    /// detached from the original code.
    ///
    /// This must to be virtual otherwise the derived classes objects run()
    /// method would not be called when accessed by a base class pointer.
    virtual void start() = 0;

private:
    // Inspired by the thread code
    Element _link;
};
~/np~{DIV}
{DIV}^
A implementação da ''Critical_Section'' meta programada é simplesmente a herança privada da implementação de ''Closure'', mais a herança da classe base de todas as seções críticas, a ''Critical_Section_Base''.
^::__Listagem 38:__ Definição da ''Critical_Section'' meta programada baseada na implementação de ''Closures''::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
template<typename... Tn>
class Critical_Section: public Critical_Section_Base, private Closure<void( Tn... )>
{
    using Closure<void( Tn... )>::run;

public:
    Critical_Section(void(*_entry)(Tn ...), Tn ... an)
            : Closure<void( Tn... )>::Closure( _entry, an ... )
    {
    }

    inline void start() {
        run();
    }
};
~/np~{DIV}
{DIV}^
%%%
!!!!Argumentos Variádicos  [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]
Para poder-se criar Closures com um número variado do parâmetros, fez-se uso de um meta programa que calcula, recursivamente as posições dos parâmetros da closures.
^::__Listagem 39:__ Cálculo do index dos parâmetros da seção crítica dentro da closure::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
template<int ...>
struct MetaSequenceOfIntegers { };

template<int AccumulatedSize, typename Tn, int... GeneratedSequence>
struct GeneratorOfIntegerSequence;

template<
            int AccumulatedSize,
            typename Grouper,
            typename Head,
            typename... Tail,
            int... GeneratedSequence
        >
struct GeneratorOfIntegerSequence<
        AccumulatedSize, Grouper( Head, Tail... ), GeneratedSequence... >
{
    typedef typename GeneratorOfIntegerSequence
            <
                AccumulatedSize + sizeof(Head),
                Grouper( Tail... ),
                GeneratedSequence...,
                AccumulatedSize
            >::type type;
};

template<int AccumulatedSize, typename Grouper, int... GeneratedSequence>
struct GeneratorOfIntegerSequence<AccumulatedSize, Grouper(), GeneratedSequence...>
{
  typedef MetaSequenceOfIntegers<GeneratedSequence...> type;
};
~/np~{DIV}
{DIV}^
Este programa é executado em tempo de compilação, e para uma dada entrada, como por exemplo ''GeneratorOfIntegerSequence< 0, int(char, int, char) >::type()'', gera o seguinte código, que calcula o pacote de parâmetros ''<0, 1, 5>'', que significa que o primeiro parâmetro da função, que é o tipo ''char'', está na posição 0, enquanto o segundo parâmetro do tipo ''int'' está na posição 1, que e o último parâmetro, ''char'' está na posição 5. Tais valores devem-se aos respectivos tamanhos de ''char'' e ''int'' serem 1 e 4:
^::__Listagem 40:__ Trecho de código gerado pelo meta programa, obtido com compilador ''LLVM Clang''::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
$ clang++ -Xclang -ast-print -fsyntax-only \
  parameter_pack_sequencer_size_generator.cpp > expanded.cpp

template<> struct GeneratorOfIntegerSequence<
            0, int (char, int, char), <>>
{
    typedef typename GeneratorOfIntegerSequence<
            0 + sizeof(char), int (int, char), 0>::type type;
};

template<> struct GeneratorOfIntegerSequence<1, int (int, char), <0>>
{
    typedef typename GeneratorOfIntegerSequence<
            1 + sizeof(int), int (char), 0, 1>::type type;
};

template<> struct GeneratorOfIntegerSequence<5, int (char), <0, 1>>
{
    typedef typename GeneratorOfIntegerSequence<
            5 + sizeof(char), int (), 0, 1, 5>::type type;
};

template<> struct GeneratorOfIntegerSequence<6, int (), <0, 1, 5>>
{
    typedef MetaSequenceOfIntegers<0, 1, 5> type;
};
~/np~{DIV}
{DIV}^
Segue o meta programa que implementa closures ou functors de parâmetros variádicos:
^::__Listagem 41:__ Implementação da Closure meta programa, arquivo ''/include/utility/closure.h''::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
template<typename Tn>
class Closure;

template<typename ReturnType, typename... Tn>
class Closure<ReturnType( Tn... )>
{
public:
    typedef ReturnType(*Function)(Tn ...);
    static const unsigned int PARAMETERS_COUNT = sizeof...( Tn );
    static const unsigned int PARAMETERS_LENGTH = SIZEOF<Tn ...>::Result;

private:
    Function _entry;
    char* _parameters;

public:
    Closure(Function _entry, Tn ... an): _entry(_entry)
    {
        db<Synchronizer>(WRN) << "Closure::Closure(_entry=" << &_entry
                << ", PARAMETERS_COUNT=" << PARAMETERS_COUNT
                << ", PARAMETERS_LENGTH=" << PARAMETERS_LENGTH
                << ", sizeof=" << sizeof(*this) << ") => " << this << endl;

        if(PARAMETERS_LENGTH)
            _parameters = new char[PARAMETERS_LENGTH];

        pack_helper( _parameters, an ... );
    }

    ~Closure() {
        db<Synchronizer>(WRN) << "Closure::~Closure(this=" << this
                << ", _entry=" << &_entry << ", PARAMETERS_COUNT=" << PARAMETERS_COUNT
                << ", PARAMETERS_LENGTH=" << PARAMETERS_LENGTH
                << ", sizeof=" << sizeof(*this) << ")" << endl;

        if(PARAMETERS_LENGTH)
            delete _parameters;
    }

    inline ReturnType run() {
        return operator()();
    }

    inline ReturnType operator()() {
        return _unpack_and_run(
                typename GeneratorOfIntegerSequence< 0, int(Tn...) >::type() );
    }

private:
    template<int ...Sequence>
    inline ReturnType _unpack_and_run(MetaSequenceOfIntegers<Sequence...>)
    {
        db<Synchronizer>(WRN) << "Closure::_unpack_and_run(this=" << this << ")" << endl;
        return _entry( unpack_helper<Sequence, Tn>()... );
    }

    template<const int position, typename T>
    inline T unpack_helper()
    {
        db<Synchronizer>(WRN) << "Closure::unpack_helper(Head=" << sizeof( T )
                << ", address=" << reinterpret_cast<int *>(_parameters + position)
                << "(" << reinterpret_cast<int *>(_parameters) << ")"
                << ", position=" << position << ")" << endl;

        return *reinterpret_cast<T *>( _parameters + position );
    }

public:
    template<typename Head, typename ... Tail>
    static void pack_helper(char* pointer_address, Head head, Tail ... tail)
    {
        db<Synchronizer>(WRN) << "Closure::pack_helper(Head=" << sizeof( Head )
                << ", address=" << reinterpret_cast<int *>(pointer_address) << ")" << endl;

        *reinterpret_cast<Head *>(pointer_address) = head;
        pack_helper(pointer_address + sizeof( Head ), tail ...);
    }

    static void pack_helper(char* pointer_address) {}
};
~/np~{DIV}
{DIV}^
Em tempo de compilação, ao detectar a criação de um Objeto closure, o compilador irá criar uma definição específica para a classe Closure de acordo com os argumentos ''(function, arg1, …, argN)''. Algo similar ao exemplo a seguir:
^::__Listagem 42:__ Ilustração de um meta programa depois de compilado::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
class Closure<funcReturntype(char, …, int), char, …, int>{
  ...
}
~/np~{DIV}
{DIV}^
O tipo ''funcReturnType'' é inferido a partir do tipo de retorno de function. Os tipos ''(char, ... , int)'' são inferidos a partir dos tipos dos argumentos ''('a', …, 1)''.

Em tempo de execução, o construtor da classe Closure irá:
# Alocar memória para o atributo ''_parameters'', que é do tipo array de char, de acordo com o tamanho dos tipos dos argumentos  ''(char, ... , 1)''
# Utilizar a função ''pack_helper()'' para colocar ''('a', ... , 1)'' no array ''_parameters'', tratando o fato de possuírem de tipos diferentes.
%%%
!!!!Exemplo de Uso  [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]
Veja um exemplo completo de teste/uso das closures meta programadas:
^::__Listagem 43:__ Arquivo ''/app/closure_test.cc''::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
// EPOS Synchronizer Component Test Program
#define DEBUG_SYNC

#include <utility/closure.h>
using namespace EPOS;

template<typename ReturnType, typename ... Tn>
Closure< ReturnType(Tn ...) > create_closure( ReturnType(*_entry)( Tn ... ), Tn ... an )
{
    auto closure = new Closure< ReturnType(Tn ...) >( _entry, an ... );
    LOG( "create_closure " << closure << endl )
    return *closure;
}

template<typename ... Tn>
void test_closure(Tn ... an) {
    auto closure = create_closure(an ...);
    closure();
    LOG( "    void" << endl << endl )
}

template<typename ... Tn>
void test_closure_with_return(Tn ... an) {
    auto closure = create_closure(an ...);
    auto return_value = closure();
    LOG( "    " << return_value << endl << endl )
}

char test_function1(char arg1, int arg2, bool arg3) {
    LOG( "test_function1 " << arg1 << ", " <<  arg2 << ", " << arg3 << endl )
    return 'A';
}

char test_function2(const char* arg1, const char* arg2, char arg3) {
    LOG( "test_function2 " << arg1 << ", " <<  arg2 << ", " << arg3 << endl )
    return 'B';
}

char test_function3() {
    LOG( "test_function3 " << endl )
    return 'C';
}

void test_function4() {
    LOG( "test_function4 " << endl )
}

void test_function5(const char* arg1) {
    LOG( "test_function5 " << arg1 << endl )
}

int main()
{
    LOG( endl )
    LOG( "main: begin()" << endl )

    test_closure_with_return( &test_function1, 'a', 10, false );
    test_closure_with_return( &test_function2, "test1", "test2", 'b' );
    test_closure_with_return( &test_function3 );

    test_closure( &test_function4 );
    test_closure( &test_function5, "Testa 3" );
    test_closure( &test_function5, "Testa 4" );

    LOG( "main: exiting()" << endl )
    return 0;
}
~/np~{DIV}
{DIV}^
Resultado da execução:
^::__Listagem 44:__ Arquivo ''/app/closure_test.cc''::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
main: begin()
Closure::Closure(_entry=0x0009ff78,
        PARAMETERS_COUNT=3, PARAMETERS_LENGTH=6, sizeof=8) => 0x00097f64
Closure::pack_helper(Head=1, address=0x00097f54)
Closure::pack_helper(Head=4, address=0x00097f55)
Closure::pack_helper(Head=1, address=0x00097f59)
create_closure 0x00097f64
Closure::_unpack_and_run(this=0x0009fef4)
Closure::unpack_helper(Head=1, address=0x00097f59(0x00097f54), position=5)
Closure::unpack_helper(Head=4, address=0x00097f55(0x00097f54), position=1)
Closure::unpack_helper(Head=1, address=0x00097f54(0x00097f54), position=0)
test_function1 a, 10, 0
    A

Closure::~Closure(this=0x0009fef4,
        _entry=0x0009fef4, PARAMETERS_COUNT=3, PARAMETERS_LENGTH=6, sizeof=8)
Closure::Closure(_entry=0x0009ff74,
        PARAMETERS_COUNT=3, PARAMETERS_LENGTH=9, sizeof=8) => 0x00097f54
Closure::pack_helper(Head=4, address=0x00097f44)
Closure::pack_helper(Head=4, address=0x00097f48)
Closure::pack_helper(Head=1, address=0x00097f4c)
create_closure 0x00097f54
Closure::_unpack_and_run(this=0x0009ff34)
Closure::unpack_helper(Head=1, address=0x00097f4c(0x00097f44), position=8)
Closure::unpack_helper(Head=4, address=0x00097f48(0x00097f44), position=4)
Closure::unpack_helper(Head=4, address=0x00097f44(0x00097f44), position=0)
test_function2 test1, test2, b
    B

Closure::~Closure(this=0x0009ff34,
        _entry=0x0009ff34, PARAMETERS_COUNT=3, PARAMETERS_LENGTH=9, sizeof=8)
Closure::Closure(_entry=0x0009fe8c,
        PARAMETERS_COUNT=0, PARAMETERS_LENGTH=0, sizeof=8) => 0x00097f44
create_closure 0x00097f44
Closure::_unpack_and_run(this=0x0009fe84)
test_function3
    C

Closure::~Closure(this=0x0009fe84,
        _entry=0x0009fe84, PARAMETERS_COUNT=0, PARAMETERS_LENGTH=0, sizeof=8)
Closure::Closure(_entry=0x0009fe8c,
        PARAMETERS_COUNT=0, PARAMETERS_LENGTH=0, sizeof=8) => 0x00097f34
create_closure 0x00097f34
Closure::_unpack_and_run(this=0x0009fe84)
test_function4
    void

Closure::~Closure(this=0x0009fe84,
        _entry=0x0009fe84, PARAMETERS_COUNT=0, PARAMETERS_LENGTH=0, sizeof=8)
Closure::Closure(_entry=0x0009fe8c,
        PARAMETERS_COUNT=1, PARAMETERS_LENGTH=4, sizeof=8) => 0x00097f24
Closure::pack_helper(Head=4, address=0x00097f14)
create_closure 0x00097f24
Closure::_unpack_and_run(this=0x0009fe84)
Closure::unpack_helper(Head=4, address=0x00097f14(0x00097f14), position=0)
test_function5 Testa 3
    void

Closure::~Closure(this=0x0009fe84,
        _entry=0x0009fe84, PARAMETERS_COUNT=1, PARAMETERS_LENGTH=4, sizeof=8)
Closure::Closure(_entry=0x0009fe8c,
        PARAMETERS_COUNT=1, PARAMETERS_LENGTH=4, sizeof=8) => 0x00097f14
Closure::pack_helper(Head=4, address=0x00097f04)
create_closure 0x00097f14
Closure::_unpack_and_run(this=0x0009fe84)
Closure::unpack_helper(Head=4, address=0x00097f04(0x00097f04), position=0)
test_function5 Testa 4
    void

Closure::~Closure(this=0x0009fe84,
        _entry=0x0009fe84, PARAMETERS_COUNT=1, PARAMETERS_LENGTH=4, sizeof=8)
main: exiting()
~/np~{DIV}
{DIV}^

Dada a função ''test_function2'' do exemplo anterior como tendo a seguinte assinatura, ''char test_function2(const char *, const char *, char)'', tem-se o seguinte código meta programado, gerado durante a compilação, para criar a ''Closure'' da ''test_function2'':
^::__Listagem 45:__ Trecho de código gerado pelo meta programa, obtido com compilador ''LLVM Clang''::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
$ clang++ -Xclang -ast-print -fsyntax-only closure_test.cpp > expanded.cpp

template<> class Closure<char (const char *, const char *, char)>
{
public:
    typedef char (*Function)(const char *, const char *, char);

    static const unsigned int PARAMETERS_COUNT = sizeof...(Tn);
    static const unsigned int PARAMETERS_LENGTH = SIZEOF<
            const char *, const char *, char>::Result;

    Closure<char (const char *, const char *, char)>::Function _entry;
    char *_parameters;

    Closure(Closure<char (const char *, const char *, char)>::Function _entry,
            const char *an, const char *an, char an) : _entry(_entry)
    {
        this->_parameters = new char [PARAMETERS_LENGTH];
        pack_helper(this->_parameters, an, an, an);
    }

    ~Closure<char (const char *, const char *, char)>()
    {
        delete this->_parameters;
    }

    char operator()()
    {
        return this->_run(typename GeneratorOfIntegerSequence<
                0, int (const char *, const char *, char)>::type());
    }

private:
    template<> char _run<<0, 8, 16>>(MetaSequenceOfIntegers<0, 8, 16>)
    {
        return this->_entry(
            this->unpack_helper<0, const char *>(),
            this->unpack_helper<8, const char *>(),
            this->unpack_helper<16, char>()
        );
    }

    template<> const char *unpack_helper<0, const char *>()
    {
        return *reinterpret_cast<const char **>(this->_parameters + 0);
    }

    template<> const char *unpack_helper<8, const char *>()
    {
        return *reinterpret_cast<const char **>(this->_parameters + 8);
    }

    template<> char unpack_helper<16, char>()
    {
        return *reinterpret_cast<char *>(this->_parameters + 16);
    }

public:
    template<> static void pack_helper<const char *, <const char *, char>>(
                char *pointer_address, const char *head, const char *tail, char tail)
    {
        *reinterpret_cast<const char **>(pointer_address) = head;
        pack_helper(pointer_address + sizeof(const char *), tail, tail);
    }

    template<> static void pack_helper<const char *, <char>>(char *pointer_address,
                const char *head, char tail)
    {
        *reinterpret_cast<const char **>(pointer_address) = head;
        pack_helper(pointer_address + sizeof(const char *), tail);
    }

    template<> static void pack_helper<char, <>>(char *pointer_address, char head)
    {
        *reinterpret_cast<char *>(pointer_address) = head;
        pack_helper(pointer_address + sizeof(char));
    }

    static void pack_helper(char *pointer_address)
    {
    }
}
~/np~{DIV}
{DIV}^
%%%
!!!!Integração com Guarda  [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]
Para integrar a nova interface de ''Critical_Section'' no algoritmo do Guarda, foi necessário somente modificar o método ''Guard::submit'', que agora passa a ser um método meta programado:
^::__Listagem 46:__ Arquivo ''/include/utility/guard.h''::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
template<typename ... Tn>
void submit( void(*entry)( Tn ... ), Tn ... an )
{
    // Creates a closure with the critical section parameters
    Critical_Section<Tn ...>* cs = new (SYSTEM) Critical_Section<Tn ...>(entry, an ...);

    Element * cur = vouch(&(cs->_link));
    if (cur != reinterpret_cast<Element *>(NULL)) do {
        cur->object()->start();
        cur = clear();
    } while (cur != reinterpret_cast<Element *>(NULL));
}
~/np~{DIV}
{DIV}^
Obrigatoriamente a nossa closure que representa a seção crítica, tem que retornar ''void'', pois no contexto de execução do algoritmo do guarda, uma vez que a ''Closure'' começa a executar, a única forma que ela tem para se comunicar com a thread original é através de uma memória compartilhada, que em nosso caso é utilizado o mecanismo de ''Futures'', como já explicado.

Agora mostra-se um exemplo de uso de closures e do algoritmo do Guarda.
^::__Listagem 47:__ Arquivo ''/app/closure_guard_test.cc''::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
// EPOS Synchronizer Component Test Program
#define DEBUG_SYNC

#include <thread.h>
#include <machine.h>
#include <utility/guard.h>
#include <utility/debug_sync.h>
#include <alarm.h>

using namespace EPOS;
Guard counter_guard;

void show(char char1, const char* text1, const char* text2,
            bool bool1, bool bool2, const char* text3, int int1) {
    LOG( "    char1=" << char1 << ", text1=" << text1
        << ", text2=" << text2 << ", bool1=" << bool1 << ", bool2=" << bool2
        << ", text3=" << text3 << ", int1="  << int1  << endl )
}

int main()
{
    LOG( endl )
    LOG( "main: begin()" << endl )
    counter_guard.submit(&show, 'A', "Test 1", "Test 2", true, false, "Test 3", 10);
    counter_guard.submit(&show, 'B', "Test 4", "Test 5", false, false, "Test 6", 20);

    LOG( "main: exiting()" << endl )
    return 0;
}
~/np~{DIV}
{DIV}^
Resultado da execução:
^::__Listagem 48:__ Arquivo ''/app/closure_guard_test.cc''::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
main: begin()
Closure::Closure(_entry=0x0009ff5c,
        PARAMETERS_COUNT=7, PARAMETERS_LENGTH=19, sizeof=8) => 0x00097f68
Closure::pack_helper(Head=1, address=0x00097f45)
Closure::pack_helper(Head=4, address=0x00097f46)
Closure::pack_helper(Head=4, address=0x00097f4a)
Closure::pack_helper(Head=1, address=0x00097f4e)
Closure::pack_helper(Head=1, address=0x00097f4f)
Closure::pack_helper(Head=4, address=0x00097f50)
Closure::pack_helper(Head=4, address=0x00097f54)
Closure::_unpack_and_run(this=0x00097f68)
Closure::unpack_helper(Head=4, address=0x00097f54(0x00097f45), position=15)
Closure::unpack_helper(Head=4, address=0x00097f50(0x00097f45), position=11)
Closure::unpack_helper(Head=1, address=0x00097f4f(0x00097f45), position=10)
Closure::unpack_helper(Head=1, address=0x00097f4e(0x00097f45), position=9)
Closure::unpack_helper(Head=4, address=0x00097f4a(0x00097f45), position=5)
Closure::unpack_helper(Head=4, address=0x00097f46(0x00097f45), position=1)
Closure::unpack_helper(Head=1, address=0x00097f45(0x00097f45), position=0)
    char1=A, text1=Test 1, text2=Test 2, bool1=1, bool2=0, text3=Test 3, int1=10

Closure::~Closure(this=0x00097f68,
        _entry=0x00097f68, PARAMETERS_COUNT=7, PARAMETERS_LENGTH=19, sizeof=8)
Closure::Closure(_entry=0x0009ff5c,
        PARAMETERS_COUNT=7, PARAMETERS_LENGTH=19, sizeof=8) => 0x00097f68
Closure::pack_helper(Head=1, address=0x00097f45)
Closure::pack_helper(Head=4, address=0x00097f46)
Closure::pack_helper(Head=4, address=0x00097f4a)
Closure::pack_helper(Head=1, address=0x00097f4e)
Closure::pack_helper(Head=1, address=0x00097f4f)
Closure::pack_helper(Head=4, address=0x00097f50)
Closure::pack_helper(Head=4, address=0x00097f54)
Closure::_unpack_and_run(this=0x00097f68)
Closure::unpack_helper(Head=4, address=0x00097f54(0x00097f45), position=15)
Closure::unpack_helper(Head=4, address=0x00097f50(0x00097f45), position=11)
Closure::unpack_helper(Head=1, address=0x00097f4f(0x00097f45), position=10)
Closure::unpack_helper(Head=1, address=0x00097f4e(0x00097f45), position=9)
Closure::unpack_helper(Head=4, address=0x00097f4a(0x00097f45), position=5)
Closure::unpack_helper(Head=4, address=0x00097f46(0x00097f45), position=1)
Closure::unpack_helper(Head=1, address=0x00097f45(0x00097f45), position=0)
    char1=B, text1=Test 4, text2=Test 5, bool1=0, bool2=0, text3=Test 6, int1=20

Closure::~Closure(this=0x00097f68,
        _entry=0x00097f68, PARAMETERS_COUNT=7, PARAMETERS_LENGTH=19, sizeof=8)
main: exiting()
~/np~{DIV}
{DIV}^

!!Testes [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]
Cria-se um arquivo de testes baseado no exemplo de http://pages.cs.wisc.edu/~remzi/OSTEP/threads-intro.pdf.
# Os exemplos com o EPOS multicore, com duas CPUS, variavelmente gerava exceções, que não ocorrem na versão single core. Não pode-se identificar exatamente qual a causa dessas exceções, que são do tipo GPF e PF. Uma constatação importante é que essas exceções ocorrem mesmo em versões minimamente modificadas das aplicações de testes padrões do EPOS.
# Por duas vezes consegue-se fazer a contagem falhar, ambas vezes utilizando o critério de escalonamento RR. No entanto, nas últimas muitas execuções a contagem voltou a ocorrer corretamente, o que é indesejado, mesmo com a utilização do escalonamento RR. Com duas CPUS.
# Foram definidos três programas de teste para a aplicação contadora simples: uma sem sincronização, uma utilizando semáforos e outra com guardas.
Todos os testes a seguir foram realizados utilizando ''static const unsigned int CPUS = 4''.

!!!fas_test.cc [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]
Aqui testa-se a implementação nova de FAS feita, repetidamente fazendo a troca de variáveis em duas thread executando em CPUs diferentes.
^::__Listagem 49:__ Arquivo de Teste ''/app/fas_test.cc''::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
// EPOS Synchronizer Component Test Program
#define DEBUG_SYNC

#include <utility/ostream.h>
#include <utility/debug_sync.h>
#include <semaphore.h>
#include <thread.h>
#include <machine.h>
#include <cpu.h>

using namespace EPOS;
static const int iterations = 1e5;

int old = 0;
int current = 10;
int next = 11;

#define check(thread, name) \
    LOG( thread << name \
            << ", old=" << old \
            << ", current=" << current \
            << ", next=" << next \
            << endl )

int myThread1() {
    check("Thread 1", ", begin")

    for (int i = 0; i < iterations; i++)
    {
        old = CPU::fas(current, next);
        current = CPU::fas(next, old);
        next = CPU::fas(old, current);
        // check("Thread 1", ", now")
    }

    check("Thread 1", ", result")
    return 0;
}

int myThread2() {
    check("Thread 2", ", begin")

    for (int i = 0; i < iterations; i++) {
        old = CPU::fas(current, next);
        current = CPU::fas(next, old);
        next = CPU::fas(old, current);
        // check("Thread 2", ", now")
    }

    check("Thread 2", ", result")
    return 0;
}

int main()
{
    LOG( endl )
    LOG( "iterations=" << iterations << endl )
    Thread p1(&myThread1);
    Thread p2(&myThread2);

    check("Thread 0", ", main")
    p1.join();
    p2.join();

    check("Thread 0", ", end")
    return 0;
}
~/np~{DIV}
{DIV}^
Resultado da execução:
^::__Listagem 50:__ Arquivo ''/app/fas_test.cc''::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
<1>: MMU is disabled! :<1>
<2>: MMU is disabled! :<2>
<3>: MMU is disabled! :<3>
<0>: iterations=100000 :<0>
<0>: Thread 0, main, old=0, current=10, next=11 :<0>
<2>: Thread 1, begin, old=0, current=10, next=11 :<2>
<1>: Thread 2, begin, old=10, current=10, next=11 :<1>
<2>: Thread 1, result, old=10, current=10, next=11 :<2>
<1>: Thread 2, result, old=10, current=10, next=11 :<1>
<1>: Thread 0, end, old=10, current=10, next=11 :<1>
<0>: The last thread has exited! :<0>
<0>: Rebooting the machine ... :<0>
~/np~{DIV}
{DIV}^

!!!count_sync_guard.cc [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]
Neste teste, utiliza-se a implementação do guarda para controlar o acesso a seção crítica ''increment_counter()'', que simplesmente soma um contador. No final da execução, espera-se que resultado da conta seja precisamente o número de iterações feita.
^::__Listagem 51:__ Arquivo de teste ''/app/count_sync_guard.cc''::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
// EPOS Synchronizer Component Test Program
#define DEBUG_SYNC

#include <thread.h>
#include <machine.h>
#include <utility/guard.h>
#include <alarm.h>

using namespace EPOS;

static volatile int counter = 0;
static const int iterations = 1e3;

Guard counter_guard;
Guard display_guard;
Thread * pool[5];

void show(char arg, const char * type) {
    LOG( arg << ": " << type << " (counter=" << counter << ")" << endl )
}

void increment_counter() {
    counter = counter + 1;
    LOG( "increment_counter (counter=" << counter << ")" << endl )
}

int mythread(char arg) {
    display_guard.submit(&show, arg, "begin");

    for (int i = iterations; i > 0 ; i--) {
        counter_guard.submit(&increment_counter);
        // Delay label(1000);
    }

    display_guard.submit(&show, arg, "end");
    return 0;
}

int main()
{
    LOG( endl )
    LOG( "main: begin (counter=" << counter << ")" << endl )

    pool[0] = new Thread(&mythread, 'A');
    pool[1] = new Thread(&mythread, 'B');
    pool[2] = new Thread(&mythread, 'C');
    pool[3] = new Thread(&mythread, 'D');
    pool[4] = new Thread(&mythread, 'E');

    LOG( "main: start joining the threads (counter=" << counter << ")" << endl )
    pool[0]->join();
    pool[1]->join();
    pool[2]->join();
    pool[3]->join();
    pool[4]->join();

    LOG( "main: done with both (counter=" << counter << ")" << endl )
    delete pool[0];
    delete pool[1];
    delete pool[2];
    delete pool[3];
    delete pool[4];

    LOG( "main: exiting (counter=" << counter << ")" << endl )
    return 0;
}
~/np~{DIV}
{DIV}^
Resultado da execução:
^::__Listagem 52:__ Arquivo ''/app/fas_test.cc''::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
<1>: MMU is disabled! :<1>
<2>: MMU is disabled! :<2>
<3>: MMU is disabled! :<3>
<0>:  :<0>
main: begin (counter=0)
<0>: main: start joining the threads (counter=0) :<0>
<0>: A: begin (counter=0) :<0>
<1>: B: begin (counter=1476) :<1>
<1>: C: begin (counter=7900) :<1>
<3>: D: begin (counter=11002) :<3>
<2>: C: end (counter=12407) :<2>
<2>: E: begin (counter=18387) :<2>
<2>: A: end (counter=25320) :<2>
<3>: D: end (counter=27383) :<3>
<2>: E: end (counter=33451) :<2>
<2>: B: end (counter=50000) :<2>
<2>: main: done with both (counter=50000) :<2>
<2>: main: exiting (counter=50000) :<2>
<0>:  :<0>
The last thread has exited!
<0>: Rebooting the machine ... :<0>
~/np~{DIV}
{DIV}^

!!!count_sync_uncoordinated.cc [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]
O que se espera deste teste, ao contrário do teste anterior, é que a contagem final de errada, pois nenhuma primitiva de sincronização é utilizada, assim tem-se que a operação de incremento, que não é atômica, seja interrompida pelo metade, e no fim o resultado fique errado.
^::__Listagem 53:__ Arquivo de teste ''/app/count_sync_uncoordinated.cc''::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
// EPOS Synchronizer Component Test Program
#define DEBUG_SYNC

#include <semaphore.h>
#include <utility/debug_sync.h>
#include <thread.h>
#include <machine.h>
#include <alarm.h>

using namespace EPOS;
int counter = 0;

// mythread()
// Simply adds 1 to counter repeatedly, in a loop
// No, this is not how you would add 10,000,000 to
// a counter, but it shows the problem nicely.
int mythread(char arg) {
    LOG( arg << ": begin : " << endl)

    for (int i = 0; i < 1e6; i++) {
        if (counter%100000 == 0){
            LOG( arg << " : " << counter << endl )
        }
        counter = counter + 1;
        // LOG( "Counting " << counter << endl )
    }

    LOG( arg << ": done" << endl )
    return 0;
}

// main()
// Just launches two threads (pthread_create)
// and then waits for them (pthread_join)
int main()
{
    LOG( endl )
    LOG( "main: begin (counter = " << counter << ")" << endl )

    Thread * p1 = new Thread(&mythread, 'A');
    Thread * p2 = new Thread(&mythread, 'B');
    Thread * p3 = new Thread(&mythread, 'C');
    Thread * p4 = new Thread(&mythread, 'D');
    Thread * p5 = new Thread(&mythread, 'E');
    Thread * p6 = new Thread(&mythread, 'F');

    // join waits for the threads to finish
    p1->join();
    p2->join();
    p3->join();
    p4->join();
    p5->join();
    p6->join();

    LOG( "main: done with both (counter = " << counter << ")"<< endl )
    return 0;
}
~/np~{DIV}
{DIV}^
Resultado da execução:
^::__Listagem 54:__ Arquivo ''/app/count_sync_uncoordinated.cc''::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
<1>: MMU is disabled! :<1>
<2>: MMU is disabled! :<2>
<3>: MMU is disabled! :<3>
<0>: main: begin (counter = 0) :<0>
<2>: A: begin :  :<2>
<2>: A : 0 :<2>
<1>: B: begin :  :<1>
<3>: C: begin :  :<3>
<0>: D: begin :  :<0>
<2>: E: begin :  :<2>
<1>: F: begin :  :<1>
<1>: F : 100000 :<1>
<2>: E : 100000 :<2>
<3>: A : 100000 :<3>
<0>: B : 100000 :<0>
<2>: C : 100000 :<2>
<1>: D : 100000 :<1>
<0>: F : 200000 :<0>
<3>: C : 200000 :<3>
<2>: E : 200000 :<2>
<3>: A : 200000 :<3>
<0>: B : 200000 :<0>
<1>: D : 200000 :<1>
<3>: E : 300000 :<3>
<0>: F : 300000 :<0>
<2>: A : 300000 :<2>
<2>: A : 300000 :<2>
<3>: C : 300000 :<3>
<2>: E : 400000 :<2>
<1>: F : 400000 :<1>
<1>: D : 345974 :<1>
<1>: B : 400000 :<1>
<3>: D : 346916 :<3>
<0>: F : 385967 :<0>
<0>: E : 393666 :<0>
<2>: A : 400000 :<2>
<1>: C : 477901 :<1>
<0>: F : 498945 :<0>
<3>: D : 446608 :<3>
<1>: E : 476901 :<1>
<0>: B : 484604 :<0>
<3>: C : 500000 :<3>
<1>: E : 528187 :<1>
<0>: D : 525792 :<0>
<2>: A : 571028 :<2>
<2>: F : 600000 :<2>
<1>: E : 567826 :<1>
<3>: A : 654100 :<3>
<1>: B : 588204 :<1>
<1>: E : 600000 :<1>
<3>: D : 689233 :<3>
<0>: B : 700000 :<0>
<0>: A : 600000 :<0>
<0>: D : 646539 :<0>
<3>: F : 658486 :<3>
<1>: C : 691064 :<1>
<0>: D : 700000 :<0>
<0>: D : 700000 :<0>
<1>: C : 700000 :<1>
<3>: F : 700000 :<3>
<2>: A : 700000 :<2>
<3>: B : 700000 :<3>
<0>: E : 700000 :<0>
<0>: C : 800000 :<0>
<3>: A : 800000 :<3>
<0>: D : 800000 :<0>
<1>: F : 817259 :<1>
<2>: B : 800000 :<2>
<2>: D : 900000 :<2>
<2>: D : 800000 :<2>
<3>: E : 800000 :<3>
<0>: C : 900000 :<0>
<2>: A : 900000 :<2>
<3>: F : 900000 :<3>
<2>: B : 900000 :<2>
<0>: D : 900000 :<0>
<3>: C : 1000000 :<3>
<2>: F : 1000000 :<2>
<3>: E : 900000 :<3>
<1>: A : 1000000 :<1>
<1>: A : 1000000 :<1>
<0>: B : 1000000 :<0>
<3>: F : 1100000 :<3>
<3>: C : 1100000 :<3>
<0>: D : 1000000 :<0>
<1>: E : 1000000 :<1>
<2>: B : 1100000 :<2>
<3>: C : 1100000 :<3>
<0>: A: done :<0>
<1>: F: done :<1>
<3>: B: done :<3>
<0>: C: done :<0>
<1>: E: done :<1>
<2>: D : 1100000 :<2>
<2>: D: done :<2>
<2>: main: done with both (counter = 1106138) :<2>
<0>: The last thread has exited! :<0>
<0>: Rebooting the machine ... :<0>
~/np~{DIV}
{DIV}^

!!!count_sync_semaphore_simple.cc [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]
Neste teste, utiliza-se os mecanismo de sincronização do semáforo, e ao contrário do teste anterior ''count_sync_uncoordinated.cc'', deste teste espera-se que a contagem seja correta, pois utiliza-se o mecanismo de sincronização do semáforo para garantir a atomicidade da operação de adição.
^::__Listagem 55:__ Arquivo de teste ''/app/count_sync_semaphore_simple.cc''::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
// EPOS Synchronizer Component Test Program
#define DEBUG_SYNC

#include <utility/debug_sync.h>
#include <semaphore.h>
#include <thread.h>
#include <machine.h>

using namespace EPOS;
static volatile int counter = 0;

Semaphore counter_lock;

// mythread()
// Simply adds 1 to counter repeatedly, in a loop
// No, this is not how you would add 10,000,000 to
// a counter, but it shows the problem nicely.
int mythread(char arg) {
    LOG( arg << ": begin" << endl )
    for (int i = 0; i < 1e4; i++) {
        counter_lock.p();
        counter = counter + 1;
        counter_lock.v();
    }

    LOG( arg << ": done" << endl )
    return 0;
}

// main()
// Just launches two threads (pthread_create)
// and then waits for them (pthread_join)
int main()
{
    LOG( endl )
    LOG( "main: begin (counter = " << counter << ")" << endl )

    Thread p1(&mythread, 'A');
    Thread p2(&mythread, 'B');

    // join waits for the threads to finish
    p1.join();
    p2.join();

    LOG( "main: done with both (counter = " << counter << ")"<< endl )
    return 0;
}
~/np~{DIV}
{DIV}^
Resultado da execução:
^::__Listagem 56:__ Arquivo ''/app/count_sync_semaphore_simple.cc''::
{DIV(type="span")}
{DIV(type="pre" bg="#CCFFFF")}~np~
<1>: MMU is disabled! :<1>
<2>: MMU is disabled! :<2>
<3>: MMU is disabled! :<3>
<0>: main: begin (counter = 0) :<0>
<0>: A: begin :<0>
<0>: B: begin :<0>
<3>: B: done :<3>
<3>: A: done :<3>
<3>: main: done with both (counter = 20000) :<3>
<0>: The last thread has exited! :<0>
<0>: Rebooting the machine ... :<0>
~/np~{DIV}
{DIV}^

!!!O que aprendemos com os testes [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]
# Executar aplicações com mais de 1 CPU ativa variavelmente gera exceções (GPF). Isso acontece mesmo com a aplicação do jantar dos filósofos, se os delays forem removidos.
# Quando requisições são enviadas ao sequencer em uma taxa maior do que ele consegue executar, a memória enche e exceções (PF) ocorrem.
# Com o KVM não funciona o relógio e o escalonador não era chamado.
# Sem o RR fica difícil gerar erros de sincronização.
# Após a primeira execução, o qemu fica muito comportado e para de gerar erros de contagem durante a execução do arquivo corrente mais simples: ''count_sync_uncoordinated.cc''
# Compilando o EPOS utilizado/entregado no trabalho anterior de 2017.2 com GCC 7.2.0, não executa a aplicação principal. Baixamos o código deles, e compilamos. A seguir tem um log completo no modo histérico da execução, mostrando o problema: https://gist.github.com/evandrocoan/3159d9bf1c53620e2e01169d7a4b8d92

!!Referências de Implementação  [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]
# https://stackoverflow.com/questions/18847424/c-create-custom-function-dispatcher-from-variadic-template
# https://stackoverflow.com/questions/42047795/order-of-parameter-pack-expansion
# https://stackoverflow.com/questions/29194858/order-of-function-calls-in-variadic-template-expansion
# https://stackoverflow.com/questions/43553585/how-to-transform-a-variadic-template-argument-to-another-types-for-calling-anoth
# https://stackoverflow.com/questions/12030538/calling-a-function-for-each-variadic-template-argument-and-an-array
# https://stackoverflow.com/questions/687490/how-do-i-expand-a-tuple-into-variadic-template-functions-arguments/12650100#12650100
# https://stackoverflow.com/questions/7858817/unpacking-a-tuple-to-call-a-matching-function-pointer
# https://en.cppreference.com/w/cpp/language/list_initialization#Notes
# https://stackoverflow.com/questions/47207621/build-function-parameters-with-variadic-templates
# https://stackoverflow.com/questions/16868129/how-to-store-variadic-template-arguments
# https://stackoverflow.com/questions/43026550/how-to-define-a-class-that-can-save-variadic-template-arguments
# https://stackoverflow.com/questions/17996003/how-to-save-variable-number-of-arguments-using-variadic-template-arguments
# https://stackoverflow.com/questions/29220248/is-it-possible-to-store-variadic-arguments-into-a-member-variable
# https://stackoverflow.com/questions/4691657/is-it-possible-to-store-a-template-parameter-pack-without-expanding-it
# https://arne-mertz.de/2016/11/modern-c-features-variadic-templates/
# https://gitlab.com/evandro-crr/epos2/tree/master
# https://stackoverflow.com/questions/13108663/storing-functions-call-and-list-of-parameters-to-invoke-later
# https://stackoverflow.com/questions/4926433/saving-function-pointerarguments-for-later-use
# https://appuals.com/fix-cannot-execute-binary-file-exec-format-error-ubuntu/
# https://stackoverflow.com/questions/30926764/extracting-function-argument-types-as-a-parameter-pack
# https://stackoverflow.com/questions/24948277/unpacking-arguments-of-a-functional-parameter-to-a-c-template-class
# https://stackoverflow.com/questions/14783876/c-is-it-possible-to-extract-class-and-argument-types-from-a-member-function
# https://stackoverflow.com/questions/34836104/how-to-extract-a-selected-set-of-arguments-of-a-variadic-function-and-use-them-t
# https://stackoverflow.com/questions/28033251/can-you-extract-types-from-template-parameter-function-signature
# https://stackoverflow.com/questions/11056714/c-type-traits-to-extract-template-parameter-class
# https://stackoverflow.com/questions/32674839/variadic-member-function-of-template-class
# https://stackoverflow.com/questions/49217891/class-member-function-in-variadic-template
# https://stackoverflow.com/questions/50316284/how-to-achieve-variadic-virtual-member-function
# https://stackoverflow.com/questions/15599679/class-member-function-pointer
# https://stackoverflow.com/questions/40855835/how-do-you-typedef-a-function-pointer-type-with-parameter-pack-arguments
# https://stackoverflow.com/questions/8915797/calling-a-function-through-its-address-in-memory-in-c-c
# https://stackoverflow.com/questions/47005664/call-function-by-known-address-c
# https://en.cppreference.com/w/cpp/language/parameter_pack
# https://stackoverflow.com/questions/47037395/forward-types-in-variadic-template-as-values-references-according-to-function-si
# https://eli.thegreenplace.net/2014/perfect-forwarding-and-universal-references-in-c
# https://stackoverflow.com/questions/3836648/structure-or-class-with-variable-number-of-members
# https://stackoverflow.com/questions/43069213/c-class-template-for-automatic-getter-setter-methods-good-bad-practice
# https://stackoverflow.com/questions/13980157/c-class-with-template-member-variable
# https://stackoverflow.com/questions/6261375/how-to-declare-data-members-that-are-objects-of-any-type-in-a-class
# https://stackoverflow.com/questions/1872220/is-it-possible-to-iterate-over-arguments-in-variadic-macros
# https://stackoverflow.com/questions/11761703/overloading-macro-on-number-of-arguments
# https://groups.google.com/forum/#!topic/comp.std.c/d-6Mj5Lko_s
# https://stackoverflow.com/questions/27941661/generating-one-class-member-per-variadic-template-argument
# https://stackoverflow.com/questions/14919990/c-how-to-template-a-class-attribute-and-not-the-functions-of-the-class
# https://stackoverflow.com/questions/40204338/template-parameter-pack-attribute
# https://stackoverflow.com/questions/5723619/is-it-possible-to-create-function-local-closures-pre-c11
# https://blog.feabhas.com/2014/03/demystifying-c-lambdas/
# https://stackoverflow.com/questions/1447199/c-closures-and-templates
# http://matt.might.net/articles/c++-template-meta-programming-with-lambda-calculus/
# https://www.gnu.org/software/gcc/gcc-4.4/cxx0x_status.html
# https://stackoverflow.com/questions/25091436/expand-a-parameter-pack-with-a-counter
# https://stackoverflow.com/questions/41623422/c-expand-variadic-template-arguments-into-a-statement
# https://stackoverflow.com/questions/8526598/how-does-stdforward-work
# https://stackoverflow.com/questions/7858817/unpacking-a-tuple-to-call-a-matching-function-pointer/7858971
# https://stackoverflow.com/questions/31204084/is-it-possible-to-call-static-method-form-variadic-template-type-parameter
# https://stackoverflow.com/questions/25680461/variadic-template-pack-expansion
# https://stackoverflow.com/questions/21180346/variadic-template-unpacking-arguments-to-typename
# https://stackoverflow.com/questions/2934904/order-of-evaluation-in-c-function-parameters
# https://stackoverflow.com/questions/9566187/function-parameter-evaluation-order
# https://stackoverflow.com/questions/7728478/c-template-class-function-with-arbitrary-container-type-how-to-define-it
# https://stackoverflow.com/questions/12048221/c11-variadic-template-function-parameter-pack-expansion-execution-order
# https://stackoverflow.com/questions/34957810/variadic-templates-parameter-pack-and-its-discussed-ambiguity-in-a-parameter-li
# https://stackoverflow.com/questions/20588191/error-with-variadiac-template-parameter-pack-must-be-expanded
# https://stackoverflow.com/questions/37200391/multiple-variadic-parameter-pack-for-template-class
# https://stackoverflow.com/questions/34940875/parameter-pack-must-be-at-the-end-of-the-parameter-list-when-and-why
# https://stackoverflow.com/questions/15904288/how-to-reverse-the-order-of-arguments-of-a-variadic-template-function
# https://stackoverflow.com/questions/12906523/how-can-i-interpret-a-stackdump-file
# https://stackoverflow.com/questions/320001/using-a-stackdump-from-cygwin-executable
# https://stackoverflow.com/questions/37628530/how-to-debug-using-stackdump-file-in-cygwin
# https://stackoverflow.com/questions/8305866/how-to-analyze-a-programs-core-dump-file-with-gdb
# https://stackoverflow.com/questions/5115613/core-dump-file-analysis
# https://www.linuxquestions.org/questions/programming-9/cygwin-gcc-compiled-code-generates-a-stackdump-how-to-analyze-with-gdb-874630
# http://cygwin.1069669.n5.nabble.com/exe-stackdump-and-core-dump-files-questions-td17219.html
# https://stackoverflow.com/questions/10208233/what-comes-first-template-instantiation-vs-macro-expansion/10208278#10208278
# https://stackoverflow.com/questions/44050323/class-member-variables-based-on-variadic-template
# https://stackoverflow.com/questions/40356688/c-define-a-class-member-type-according-to-its-template
# https://stackoverflow.com/questions/11394832/how-to-define-a-template-member-function-of-a-template-class
# https://stackoverflow.com/questions/29668447/c-independent-static-variable-for-each-object-inside-a-method
# http://www.cplusplus.com/forum/general/142258/
# https://stackoverflow.com/questions/3778450/is-local-static-variable-per-instance-or-per-class
# https://stackoverflow.com/questions/347358/inheriting-constructors
# https://stackoverflow.com/questions/8887864/template-base-constructor-call-in-member-initialization-list-error
# https://stackoverflow.com/questions/25064515/how-to-call-constructor-of-a-template-base-class-in-a-template-derived-class
# https://stackoverflow.com/questions/10282787/calling-the-base-class-constructor-from-the-derived-class-constructor
# https://stackoverflow.com/questions/120876/what-are-the-rules-for-calling-the-superclass-constructor
# https://stackoverflow.com/questions/12464633/is-it-safe-to-privately-inherit-from-a-class-with-a-non-virtual-destructor
# https://stackoverflow.com/questions/2004820/inherit-interfaces-which-share-a-method-name
# https://stackoverflow.com/questions/10535667/does-it-make-any-sense-to-use-inline-keyword-with-templates
# https://stackoverflow.com/questions/3531060/how-to-initialize-a-static-const-member-in-c
# https://stackoverflow.com/questions/34222703/how-to-override-static-method-of-template-class-in-derived-class
# https://stackoverflow.com/questions/11761506/inheritance-function-that-returns-self-type
# https://stackoverflow.com/questions/115703/storing-c-template-function-definitions-in-a-cpp-file
# https://stackoverflow.com/questions/19884494/too-few-template-parameter-lists-error
# https://stackoverflow.com/questions/5901300/how-do-i-view-previous-diff-commits-using-git
# https://stackoverflow.com/questions/2721846/alternative-to-c-static-virtual-methods
# https://stackoverflow.com/questions/34222703/how-to-override-static-method-of-template-class-in-derived-class
# https://stackoverflow.com/questions/137038/how-do-you-get-assembler-output-from-c-c-source-in-gcc
# https://stackoverflow.com/questions/34842152/compare-and-exchange-on-x86-cpu
# https://stackoverflow.com/questions/47981/how-do-you-set-clear-and-toggle-a-single-bit
# https://stackoverflow.com/questions/2064692/how-to-print-function-pointers-with-cout
# https://stackoverflow.com/questions/8747005/backporting-nullptr-to-c-pre-c0x-programs
# https://stackoverflow.com/questions/10496824/how-to-define-nullptr-for-supporting-both-c03-and-c11
# https://stackoverflow.com/questions/2741708/makefile-contains-string
# https://stackoverflow.com/questions/3531060/how-to-initialize-a-static-const-member-in-c
# https://stackoverflow.com/questions/11761506/inheritance-function-that-returns-self-type
# https://stackoverflow.com/questions/4673720/private-inheritance-using-directive-overloads
# https://stackoverflow.com/questions/656224/when-should-i-use-c-private-inheritance
# https://stackoverflow.com/questions/24609872/delete-virtual-function-from-a-derived-class
# https://stackoverflow.com/questions/18469818/class-inheritance-error-private-member
# https://stackoverflow.com/questions/9055778/initializing-a-reference-to-member-to-null-in-c

!!Referências  [#Predictable_Synchronization_Algorithms_for_Asynchronous_Critical_Sections|←]
#Stefan Reif and Wolfgang Schröder-Preikschat, "Predictable Synchronisation Algorithms for Asynchronous Critical Sections,” Friedrich-Alexander-Universität Erlangen-Nürnberg, Dept. of Computer Science, Technical Reports, CS-2018-03, February 2018.
#G. Drescher and W. Schröder-Preikschat, "Guarded sections: Structuring aid for wait-free synchronisation,” in Proceedings of the 18th International Symposium On Real-Time Computing (ISORC 2015). IEEE Computer Society Press, 2015, pp. 280–283.
#S. Reif, T. Hönig, and W. Schröder-Preikschat. 2017. In the Heat of Conflict: On the Synchronisation of Critical Sections. In IEEE ISORC ’17. 42–51.
#D. Klaftenegger, K. Sagonas, and K. Winblad, "Brief announcement: Queue delegation locking,” in Proceedings of the 26th ACM Symposium on Parallelism in Algorithms and Architectures (SPAA 2014). ACM Press, 2014, pp. 70–72.
#Herlihy, Maurice. "The art of multiprocessor programming.” PODC (2006).
#Håkan Sundell, "Efficient and Practical Non-Blocking Data Structures”, Chalmers University of Technology and Göteborg University, Department of Computing Science, 2004
#Jean-Pierre Lozi , Florian David , Gaël Thomas , Julia Lawall , Gilles Muller, Remote core locking: migrating critical-section execution to improve the performance of multithreaded applications, Proceedings of the 2012 USENIX conference on Annual Technical Conference, p.6-6, June 13-15, 2012, Boston, MA
#Numa And Uma And Shared Memory Multiprocessors Computer Science Essay https://www.ukessays.com/essays/computer-science/numa-and-uma-and-shared-memory-multiprocessors-computer-science-essay.php.
#Lock-free Programming Talk at Cppcon 2014 by Herb Sutter https://www.youtube.com/watch?v=c1gO9aB9nbs&list=PLLx8RvOpJ0wlFCGxWAVBTo3CoR9PYkpz2
#An Introduction to Lock-Free Programming http://preshing.com/20120612/an-introduction-to-lock-free-programming/
#Lock-Free Programming - Geoff Langdale https://www.cs.cmu.edu/~410-s05/lectures/L31_LockFree.pdf
#P. J. Landin, "The mechanical evaluation of expressions,” The Computer Journal, vol. 6, no. 4, pp. 308–320, 1964 https://www.cs.cmu.edu/~crary/819-f09/Landin64.pdf
#An Experiment in Wait-Free Synchronisation of Priority-Controlled Simultaneous Processes: Guarded Sections, 2015 https://opus4.kobv.de/opus4-fau/frontdoor/index/index/year/2015/docId/6061
#The incremental garbage collection of processes, 1977 https://dl.acm.org/citation.cfm?id=806932
#Técnicas de Processamento Assíncrono https://ine5646.gitbook.io/livro/javascript/tecnicas-de-processamento-assincrono
#How JavaScript works: ''Event loop'' and the rise of Async programming + 5 ways to better coding with async/await https://blog.sessionstack.com/how-javascript-works-event-loop-and-the-rise-of-async-programming-5-ways-to-better-coding-with-2f077c4438b5
#C++11 Multithreading – Part 8: ''std{DIV(type="span")}:{DIV}:promise'' , ''std{DIV(type="span")}:{DIV}:promise'' and Returning values from Thread https://thispointer.com/c11-multithreading-part-8-stdfuture-stdpromise-and-returning-values-from-thread/
#CPU intensive javascript computations without blocking the single thread https://benjaminhorn.io/code/cpu-intensive-javascript-computations-without-blocking-the-single-thread/
#Promise vs Observable https://stackoverflow.com/questions/37364973/promise-vs-observable
#Promises vs Observables https://medium.com/@mpodlasin/promises-vs-observables-4c123c51fe13
#When does a thread become idle? https://stackoverflow.com/questions/19784293/when-does-a-thread-become-idle
